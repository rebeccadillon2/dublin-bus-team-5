{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from patsy import dmatrices\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "import graphviz\n",
    "from graphviz import Source\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pickle\n",
    "import os \n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code adapted from https://github.com/jamie-reynolds-UCD/UCD-Dublin-Bus-App-Team9/blob/main/data/General_Files_Linreg/general_LinRegModelling.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dir_1 = pd.read_csv('/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/modelling_prep/feature_pairwise_cleaned_dir1.csv')\n",
    "df_dir_2 = pd.read_csv('/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/modelling_prep/feature_pairwise_cleaned_dir2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the direction 1 dataframe is: (354155, 13)\n",
      "The shape of the direction 2 dataframe is: (352480, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of the direction 1 dataframe is:\", df_dir_1.shape)\n",
    "print(\"The shape of the direction 2 dataframe is:\", df_dir_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The datatypes in the direction 1 dataframe is:\n",
      "temp            float64\n",
      "humidity          int64\n",
      "wind_speed      float64\n",
      "weather_id        int64\n",
      "heavy_precip      int64\n",
      "HOUR              int64\n",
      "TRIPID            int64\n",
      "LINEID           object\n",
      "ROUTEID          object\n",
      "DIRECTION         int64\n",
      "TRIPTIME        float64\n",
      "WEEKDAY           int64\n",
      "MONTH             int64\n",
      "dtype: object\n",
      "The datatypes in the direction 2 dataframe is:\n",
      "humidity          int64\n",
      "wind_speed      float64\n",
      "weather_id        int64\n",
      "heavy_precip      int64\n",
      "HOUR              int64\n",
      "TRIPID            int64\n",
      "LINEID           object\n",
      "ROUTEID          object\n",
      "DIRECTION         int64\n",
      "TRIPTIME        float64\n",
      "WEEKDAY           int64\n",
      "MONTH             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"The datatypes in the direction 1 dataframe is:\")\n",
    "print(df_dir_1.dtypes)\n",
    "print(\"The datatypes in the direction 2 dataframe is:\")\n",
    "print(df_dir_2.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direction 1\n",
    "Remembering from <i>feature_pairwise_interactions.ipynb</i> the following:<br>\n",
    "* categorical_med_info_gain = ['MONTH','heavy_precip','weather_id']\n",
    "* categorical_high_info_gain = ['HOUR','WEEKDAY']\n",
    "<br>\n",
    "\n",
    "Tried first with all features, low accuracy (R2 less than 0.2 in most cases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dir_1 = df_dir_1.drop(columns=['heavy_precip','weather_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '102',\n",
       " '104',\n",
       " '11',\n",
       " '111',\n",
       " '114',\n",
       " '116',\n",
       " '120',\n",
       " '122',\n",
       " '123',\n",
       " '13',\n",
       " '130',\n",
       " '14',\n",
       " '140',\n",
       " '142',\n",
       " '145',\n",
       " '14C',\n",
       " '15',\n",
       " '150',\n",
       " '151',\n",
       " '15A',\n",
       " '15B',\n",
       " '15D',\n",
       " '16',\n",
       " '161',\n",
       " '16C',\n",
       " '16D',\n",
       " '17',\n",
       " '17A',\n",
       " '18',\n",
       " '184',\n",
       " '185',\n",
       " '220',\n",
       " '236',\n",
       " '238',\n",
       " '239',\n",
       " '25',\n",
       " '25A',\n",
       " '25B',\n",
       " '25D',\n",
       " '25X',\n",
       " '26',\n",
       " '27',\n",
       " '270',\n",
       " '27A',\n",
       " '27B',\n",
       " '27X',\n",
       " '29A',\n",
       " '31',\n",
       " '31A',\n",
       " '31B',\n",
       " '31D',\n",
       " '32',\n",
       " '32X',\n",
       " '33',\n",
       " '33A',\n",
       " '33B',\n",
       " '33D',\n",
       " '33E',\n",
       " '33X',\n",
       " '37',\n",
       " '38',\n",
       " '38A',\n",
       " '38B',\n",
       " '38D',\n",
       " '39',\n",
       " '39A',\n",
       " '39X',\n",
       " '4',\n",
       " '40',\n",
       " '40B',\n",
       " '40D',\n",
       " '40E',\n",
       " '41',\n",
       " '41B',\n",
       " '41C',\n",
       " '41D',\n",
       " '41X',\n",
       " '42',\n",
       " '42D',\n",
       " '43',\n",
       " '44',\n",
       " '44B',\n",
       " '45A',\n",
       " '46A',\n",
       " '47',\n",
       " '49',\n",
       " '51D',\n",
       " '53',\n",
       " '54A',\n",
       " '56A',\n",
       " '59',\n",
       " '61',\n",
       " '63',\n",
       " '65',\n",
       " '65B',\n",
       " '66',\n",
       " '66A',\n",
       " '66B',\n",
       " '66X',\n",
       " '67',\n",
       " '67X',\n",
       " '68',\n",
       " '68A',\n",
       " '69',\n",
       " '69X',\n",
       " '7',\n",
       " '70',\n",
       " '70D',\n",
       " '75',\n",
       " '76',\n",
       " '76A',\n",
       " '77A',\n",
       " '79',\n",
       " '79A',\n",
       " '7A',\n",
       " '7B',\n",
       " '7D',\n",
       " '83',\n",
       " '83A',\n",
       " '84',\n",
       " '84A',\n",
       " '84X',\n",
       " '9']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_dir_1 = sorted(list(df_dir_1['LINEID'].unique()))\n",
    "lines_dir_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough values for line 41D\n"
     ]
    }
   ],
   "source": [
    "# Make dictionaries with keys for each stop with each train/test split value as its values.\n",
    "\n",
    "X_train_dict_1 = {}\n",
    "y_train_dict_1 = {}\n",
    "X_test_dict_1 ={}\n",
    "y_test_dict_1 = {}\n",
    "\n",
    "for line in lines_dir_1:\n",
    "    \n",
    "    df_line = df_dir_1[df_dir_1['LINEID']==line]\n",
    "    \n",
    "    #check for df with low values\n",
    "    if df_line.shape[0] < 3:\n",
    "        print('Not enough values for line', str(line))\n",
    "        lines_dir_1.remove(line)\n",
    "\n",
    "    else:\n",
    "        # randomly generate sequence based on dataframe index and set to be new index\n",
    "        df_line.set_index(np.random.permutation(df_line.index))\n",
    "        # sort the resulting random index\n",
    "        df_line.sort_index(inplace=True)\n",
    "\n",
    "        \n",
    "        # drop unneeded columns\n",
    "        df_line.drop(columns=['TRIPID', 'ROUTEID', 'DIRECTION','LINEID'], inplace=True)\n",
    "\n",
    "        X = df_line.drop([\"TRIPTIME\"],1)\n",
    "        y = pd.DataFrame(df_line['TRIPTIME'])\n",
    "\n",
    "        # do test train split\n",
    "        # Split the dataset into two datasets: 70% training and 30% test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=1)\n",
    "\n",
    "        X_train_dict_1[line] = X_train\n",
    "        y_train_dict_1[line] = y_train\n",
    "        X_test_dict_1[line] = X_test\n",
    "        y_test_dict_1[line] = y_test\n",
    "        \n",
    "        # need to reset the index to allow contatenation with predicted values otherwise not joining on same index...\n",
    "        X_train.reset_index(drop=True, inplace=True)\n",
    "        y_train.reset_index(drop=True, inplace=True)\n",
    "        X_test.reset_index(drop=True, inplace=True)\n",
    "        y_test.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict_1 = {}\n",
    "\n",
    "for line in lines_dir_1:\n",
    "    print(f'Line {line}')\n",
    "    \n",
    "    X_train_dict_1[line] = X_train\n",
    "    y_train_dict_1[line] = y_train\n",
    "    X_test_dict_1[line] = X_test\n",
    "    y_test_dict_1[line] = y_test\n",
    "\n",
    "    linReg = LinearRegression().fit(X_train, y_train)\n",
    "    \n",
    "    model_dict_1[line] = linReg\n",
    "\n",
    "    # code from https://stackoverflow.com/questions/11660605/how-to-overwrite-a-folder-if-it-already-exists-when-creating-it-with-makedirs\n",
    "\n",
    "    dir = f'/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/linearregression/picklefiles/line_{line}_model/dir1'\n",
    "    if os.path.exists(dir):\n",
    "        shutil.rmtree(dir)\n",
    "    os.makedirs(dir)\n",
    "    \n",
    "    filename = f'/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/linearregression/picklefiles/line_{line}_model/dir1/line_{line}_linreg.sav'\n",
    "    pickle.dump(linReg, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines_dir_1:  \n",
    "\n",
    "    # training data\n",
    "    X_train = X_train_dict_1[line]\n",
    "    y_train = y_train_dict_1[line]\n",
    "    linReg = model_dict_1[line]\n",
    "    \n",
    "    # test data\n",
    "    X_test = X_test_dict_1[line]\n",
    "    y_test = y_test_dict_1[line]\n",
    "    linReg = model_dict_1[line]\n",
    "            \n",
    "    print('Now modelling for line', str(line))\n",
    "    \n",
    "    linReg_predictions_train = list(linReg.predict(X_train))\n",
    "\n",
    "    # train metrics\n",
    "    train_mae = metrics.mean_absolute_error(y_train, linReg_predictions_train)\n",
    "    train_mape = metrics.mean_absolute_percentage_error(y_train, linReg_predictions_train)\n",
    "    train_mse = metrics.mean_squared_error(y_train, linReg_predictions_train)\n",
    "    train_rmse = metrics.mean_squared_error(y_train, linReg_predictions_train)**(0.5)\n",
    "    train_r2 = metrics.r2_score(y_train, linReg_predictions_train)\n",
    "\n",
    "    linReg_predictions_test = list(linReg.predict(X_test))\n",
    "\n",
    "    # test metrics\n",
    "    test_mae = metrics.mean_absolute_error(y_test, linReg_predictions_test)\n",
    "    test_mape = metrics.mean_absolute_percentage_error(y_test, linReg_predictions_test)\n",
    "    test_mse = metrics.mean_squared_error(y_test, linReg_predictions_test)\n",
    "    test_rmse = metrics.mean_squared_error(y_test, linReg_predictions_test)**(0.5)\n",
    "    test_r2 = metrics.r2_score(y_test, linReg_predictions_test)\n",
    "    \n",
    "    with open(f'/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/linearregression/picklefiles/line_{line}_model/dir1/line_{line}_linreg_metrics.csv', 'w') as file:\n",
    "        file.write(f'\\nTrain metrics for line {line}:'\n",
    "                f'\\nMAE: {train_mae}' +\\\n",
    "                f'\\nMAPE: {train_mape}'+\\\n",
    "                f'\\nMSE: {train_mse}'+\\\n",
    "                f'\\nRMSE: {train_rmse**(0.5)}'+\\\n",
    "                f'\\nR2: {train_r2}'+\\\n",
    "                f'\\nTest metrics for line {line}:'\n",
    "                f'\\nMAE: {test_mae}' +\\\n",
    "                f'\\nMAPE: {test_mape}'+\\\n",
    "                f'\\nMSE: {test_mse}'+\\\n",
    "                f'\\nRMSE: {test_rmse**(0.5)}'+\\\n",
    "                f'\\nR2: {test_r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines_dir_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 1\n",
      "Line 102\n",
      "Line 104\n",
      "Line 11\n",
      "Line 111\n",
      "Line 114\n",
      "Line 116\n",
      "Line 120\n",
      "Line 122\n",
      "Line 123\n",
      "Line 13\n",
      "Line 130\n",
      "Line 14\n",
      "Line 140\n",
      "Line 142\n",
      "Line 145\n",
      "Line 14C\n",
      "Line 15\n",
      "Line 150\n",
      "Line 151\n",
      "Line 15A\n",
      "Line 15B\n",
      "Line 15D\n",
      "Line 16\n",
      "Line 161\n",
      "Line 16C\n",
      "Line 16D\n",
      "Line 17\n",
      "Line 17A\n",
      "Line 18\n",
      "Line 184\n",
      "Line 185\n",
      "Line 220\n",
      "Line 236\n",
      "Line 238\n",
      "Line 239\n",
      "Line 25\n",
      "Line 25A\n",
      "Line 25B\n",
      "Line 25D\n",
      "Line 25X\n",
      "Line 26\n",
      "Line 27\n",
      "Line 270\n",
      "Line 27A\n",
      "Line 27B\n",
      "Line 27X\n",
      "Line 29A\n",
      "Line 31\n",
      "Line 31A\n",
      "Line 31B\n",
      "Line 31D\n",
      "Line 32\n",
      "Line 32X\n",
      "Line 33\n",
      "Line 33A\n",
      "Line 33B\n",
      "Line 33D\n",
      "Line 33E\n",
      "Line 33X\n",
      "Line 37\n",
      "Line 38\n",
      "Line 38A\n",
      "Line 38B\n",
      "Line 38D\n",
      "Line 39\n",
      "Line 39A\n",
      "Line 39X\n",
      "Line 4\n",
      "Line 40\n",
      "Line 40B\n",
      "Line 40D\n",
      "Line 40E\n",
      "Line 41\n",
      "Line 41B\n",
      "Line 41C\n",
      "Line 41X\n",
      "Line 42\n",
      "Line 42D\n",
      "Line 43\n",
      "Line 44\n",
      "Line 44B\n",
      "Line 45A\n",
      "Line 46A\n",
      "Line 47\n",
      "Line 49\n",
      "Line 51D\n",
      "Line 53\n",
      "Line 54A\n",
      "Line 56A\n",
      "Line 59\n",
      "Line 61\n",
      "Line 63\n",
      "Line 65\n",
      "Line 65B\n",
      "Line 66\n",
      "Line 66A\n",
      "Line 66B\n",
      "Line 66X\n",
      "Line 67\n",
      "Line 67X\n",
      "Line 68\n",
      "Line 68A\n",
      "Line 69\n",
      "Line 69X\n",
      "Line 7\n",
      "Line 70\n",
      "Line 70D\n",
      "Line 75\n",
      "Line 76\n",
      "Line 76A\n",
      "Line 77A\n",
      "Line 79\n",
      "Line 79A\n",
      "Line 7A\n",
      "Line 7B\n",
      "Line 7D\n",
      "Line 83\n",
      "Line 83A\n",
      "Line 84\n",
      "Line 84A\n",
      "Line 84X\n",
      "Line 9\n"
     ]
    }
   ],
   "source": [
    "rf_model_dict_1 = {}\n",
    "\n",
    "for line in lines_dir_1:\n",
    "    print(f'Line {line}')\n",
    "    \n",
    "    X_train_dict_1[line] = X_train\n",
    "    y_train_dict_1[line] = y_train\n",
    "    X_test_dict_1[line] = X_test\n",
    "    y_test_dict_1[line] = y_test\n",
    "\n",
    "    rfr = RandomForestRegressor(n_estimators=50, max_features='auto', oob_score=True, random_state=1)\n",
    "    result = rfr.fit(X_train, y_train)\n",
    "    rf_model_dict_1[line] = rfr\n",
    "\n",
    "    # code from https://stackoverflow.com/questions/11660605/how-to-overwrite-a-folder-if-it-already-exists-when-creating-it-with-makedirs\n",
    "\n",
    "    dir = f'/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/randomforest/picklefiles/line_{line}_model/dir1'\n",
    "    if os.path.exists(dir):\n",
    "        shutil.rmtree(dir)\n",
    "    os.makedirs(dir)\n",
    "    \n",
    "    filename = f'/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/randomforest/picklefiles/line_{line}_model/dir1/line_{line}_rfr.sav'\n",
    "    pickle.dump(rfr, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now modelling for line 1\n",
      "Now modelling for line 102\n",
      "Now modelling for line 104\n",
      "Now modelling for line 11\n",
      "Now modelling for line 111\n",
      "Now modelling for line 114\n",
      "Now modelling for line 116\n",
      "Now modelling for line 120\n",
      "Now modelling for line 122\n",
      "Now modelling for line 123\n",
      "Now modelling for line 13\n",
      "Now modelling for line 130\n",
      "Now modelling for line 14\n",
      "Now modelling for line 140\n",
      "Now modelling for line 142\n",
      "Now modelling for line 145\n",
      "Now modelling for line 14C\n",
      "Now modelling for line 15\n",
      "Now modelling for line 150\n",
      "Now modelling for line 151\n",
      "Now modelling for line 15A\n",
      "Now modelling for line 15B\n",
      "Now modelling for line 15D\n",
      "Now modelling for line 16\n",
      "Now modelling for line 161\n",
      "Now modelling for line 16C\n",
      "Now modelling for line 16D\n",
      "Now modelling for line 17\n",
      "Now modelling for line 17A\n",
      "Now modelling for line 18\n",
      "Now modelling for line 184\n",
      "Now modelling for line 185\n",
      "Now modelling for line 220\n",
      "Now modelling for line 236\n",
      "Now modelling for line 238\n",
      "Now modelling for line 239\n",
      "Now modelling for line 25\n",
      "Now modelling for line 25A\n",
      "Now modelling for line 25B\n",
      "Now modelling for line 25D\n",
      "Now modelling for line 25X\n",
      "Now modelling for line 26\n",
      "Now modelling for line 27\n",
      "Now modelling for line 270\n",
      "Now modelling for line 27A\n",
      "Now modelling for line 27B\n",
      "Now modelling for line 27X\n",
      "Now modelling for line 29A\n",
      "Now modelling for line 31\n",
      "Now modelling for line 31A\n",
      "Now modelling for line 31B\n",
      "Now modelling for line 31D\n",
      "Now modelling for line 32\n",
      "Now modelling for line 32X\n",
      "Now modelling for line 33\n",
      "Now modelling for line 33A\n",
      "Now modelling for line 33B\n",
      "Now modelling for line 33D\n",
      "Now modelling for line 33E\n",
      "Now modelling for line 33X\n",
      "Now modelling for line 37\n",
      "Now modelling for line 38\n",
      "Now modelling for line 38A\n",
      "Now modelling for line 38B\n",
      "Now modelling for line 38D\n",
      "Now modelling for line 39\n",
      "Now modelling for line 39A\n",
      "Now modelling for line 39X\n",
      "Now modelling for line 4\n",
      "Now modelling for line 40\n",
      "Now modelling for line 40B\n",
      "Now modelling for line 40D\n",
      "Now modelling for line 40E\n",
      "Now modelling for line 41\n",
      "Now modelling for line 41B\n",
      "Now modelling for line 41C\n",
      "Now modelling for line 41X\n",
      "Now modelling for line 42\n",
      "Now modelling for line 42D\n",
      "Now modelling for line 43\n",
      "Now modelling for line 44\n",
      "Now modelling for line 44B\n",
      "Now modelling for line 45A\n",
      "Now modelling for line 46A\n",
      "Now modelling for line 47\n",
      "Now modelling for line 49\n",
      "Now modelling for line 51D\n",
      "Now modelling for line 53\n",
      "Now modelling for line 54A\n",
      "Now modelling for line 56A\n",
      "Now modelling for line 59\n",
      "Now modelling for line 61\n",
      "Now modelling for line 63\n",
      "Now modelling for line 65\n",
      "Now modelling for line 65B\n",
      "Now modelling for line 66\n",
      "Now modelling for line 66A\n",
      "Now modelling for line 66B\n",
      "Now modelling for line 66X\n",
      "Now modelling for line 67\n",
      "Now modelling for line 67X\n",
      "Now modelling for line 68\n",
      "Now modelling for line 68A\n",
      "Now modelling for line 69\n",
      "Now modelling for line 69X\n",
      "Now modelling for line 7\n",
      "Now modelling for line 70\n",
      "Now modelling for line 70D\n",
      "Now modelling for line 75\n",
      "Now modelling for line 76\n",
      "Now modelling for line 76A\n",
      "Now modelling for line 77A\n",
      "Now modelling for line 79\n",
      "Now modelling for line 79A\n",
      "Now modelling for line 7A\n",
      "Now modelling for line 7B\n",
      "Now modelling for line 7D\n",
      "Now modelling for line 83\n",
      "Now modelling for line 83A\n",
      "Now modelling for line 84\n",
      "Now modelling for line 84A\n",
      "Now modelling for line 84X\n",
      "Now modelling for line 9\n"
     ]
    }
   ],
   "source": [
    "for line in lines_dir_1:  \n",
    "\n",
    "    # training data\n",
    "    X_train = X_train_dict_1[line]\n",
    "    y_train = y_train_dict_1[line]\n",
    "    rfr = rf_model_dict_1[line]\n",
    "    \n",
    "    # test data\n",
    "    X_test = X_test_dict_1[line]\n",
    "    y_test = y_test_dict_1[line]\n",
    "    rfr = rf_model_dict_1[line]\n",
    "            \n",
    "    print('Now modelling for line', str(line))\n",
    "    \n",
    "    rfr_predictions_train = list(rfr.predict(X_train))\n",
    "    rfr_predictions_test = list(rfr.predict(X_test))\n",
    "\n",
    "    with open(f'/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/randomforest/picklefiles/line_{line}_model/dir1/line_{line}_rfr_metrics.csv', 'w') as file:\n",
    "        file.write(f'\\nMetrics for line {line}:'\n",
    "                f'\\nMAE: {metrics.mean_absolute_error(y_train, rfr_predictions_train)}' +\\\n",
    "                f'\\nMAPE: {metrics.mean_absolute_percentage_error(y_train, rfr_predictions_train)}'+\\\n",
    "                f'\\nMSE: {metrics.mean_squared_error(y_train, rfr_predictions_train)}'+\\\n",
    "                f'\\nRMSE: {metrics.mean_squared_error(y_train, rfr_predictions_train)**(0.5)}'+\\\n",
    "                f'\\nR2: {metrics.r2_score(y_train, rfr_predictions_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOUR</td>\n",
       "      <td>0.578939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WEEKDAY</td>\n",
       "      <td>0.134704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wind_speed</td>\n",
       "      <td>0.103197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>humidity</td>\n",
       "      <td>0.096059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MONTH</td>\n",
       "      <td>0.087101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  importance\n",
       "2        HOUR    0.578939\n",
       "3     WEEKDAY    0.134704\n",
       "1  wind_speed    0.103197\n",
       "0    humidity    0.096059\n",
       "4       MONTH    0.087101"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = pd.DataFrame({'feature': X_train.columns, 'importance':rfr.feature_importances_})\n",
    "importance.sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At each adjustment checking these figures:\n",
    "1. Will drop heavy_precip (0.001122) \n",
    "- model now at 0.85\n",
    "2. Will drop weather_id (0.036889)\n",
    "- model now at 0.858\n",
    "3. Will now drop month (0.059965)\n",
    "- r2 decreased to 0.857"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_RandomForest_DF(X,y, depth=None, estimators=100):\n",
    "    \"\"\"Function to perform cross validation and store results \n",
    "    in dataframe. Cross validation looks at accuracy, precision, \n",
    "    recall, f1. Returns a dataframe with results\"\"\"\n",
    "\n",
    "    # store results in dict\n",
    "    RandomForestResults = {}\n",
    "    # metrics to test against\n",
    "    test_metrics = ['accuracy','precision','recall', 'f1']\n",
    "\n",
    "    for metric in test_metrics:\n",
    "        # generate test results\n",
    "        result = cross_val_score(RandomForestRegressor(n_estimators=estimators, max_features='auto', oob_score=True, random_state=1, max_depth=depth), X, y, scoring=metric, cv=10)\n",
    "        # store result in dict\n",
    "        RandomForestResults[metric] = result.mean()\n",
    "    \n",
    "    # create dataframe with results\n",
    "    RandomForestDF = pd.DataFrame.from_dict(RandomForestResults, orient='index', columns=['Random_Forests'])\n",
    "\n",
    "    return RandomForestDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [151]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m RandomForestDF \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_RandomForest_DF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean results from 10 fold cross validation are:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m RandomForestDF\n",
      "Input \u001b[0;32mIn [150]\u001b[0m, in \u001b[0;36mcross_val_RandomForest_DF\u001b[0;34m(X, y, depth, estimators)\u001b[0m\n\u001b[1;32m      9\u001b[0m test_metrics \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m test_metrics:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# generate test results\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRandomForestRegressor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moob_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdepth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# store result in dict\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     RandomForestResults[metric] \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rp22/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    513\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 515\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rp22/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 266\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rp22/lib/python3.8/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rp22/lib/python3.8/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rp22/lib/python3.8/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rp22/lib/python3.8/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rp22/lib/python3.8/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rp22/lib/python3.8/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rp22/lib/python3.8/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rp22/lib/python3.8/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rp22/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rp22/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:476\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    465\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    467\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    468\u001b[0m ]\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 476\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rp22/lib/python3.8/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rp22/lib/python3.8/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rp22/lib/python3.8/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rp22/lib/python3.8/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rp22/lib/python3.8/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rp22/lib/python3.8/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rp22/lib/python3.8/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rp22/lib/python3.8/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rp22/lib/python3.8/site-packages/sklearn/ensemble/_forest.py:189\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    187\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 189\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rp22/lib/python3.8/site-packages/sklearn/tree/_classes.py:1342\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1314\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1315\u001b[0m \n\u001b[1;32m   1316\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1342\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1345\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1347\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/rp22/lib/python3.8/site-packages/sklearn/tree/_classes.py:458\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    449\u001b[0m         splitter,\n\u001b[1;32m    450\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    456\u001b[0m     )\n\u001b[0;32m--> 458\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "RandomForestDF = cross_val_RandomForest_DF(X,y)\n",
    "print(f\"Mean results from 10 fold cross validation are:\")\n",
    "RandomForestDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5993010498200189"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the out-of-bag classification accuracy\n",
    "rfr.oob_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direction 2\n",
    "Remembering from <i>feature_pairwise_interactions.ipynb</i> the following:\n",
    "* categorical_med_info_gain = ['heavy_precip','weather_id','weather_main']\n",
    "* categorical_high_info_gain = ['HOUR','WEEKDAY','MONTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>weather_id</th>\n",
       "      <th>heavy_precip</th>\n",
       "      <th>HOUR</th>\n",
       "      <th>TRIPID</th>\n",
       "      <th>LINEID</th>\n",
       "      <th>ROUTEID</th>\n",
       "      <th>DIRECTION</th>\n",
       "      <th>TRIPTIME</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>MONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>5.10</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5962263</td>\n",
       "      <td>40</td>\n",
       "      <td>40_31</td>\n",
       "      <td>2</td>\n",
       "      <td>4574.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>5.10</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5963304</td>\n",
       "      <td>40</td>\n",
       "      <td>40_31</td>\n",
       "      <td>2</td>\n",
       "      <td>4106.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81</td>\n",
       "      <td>3.10</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5958381</td>\n",
       "      <td>15B</td>\n",
       "      <td>15B_61</td>\n",
       "      <td>2</td>\n",
       "      <td>3433.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81</td>\n",
       "      <td>3.10</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5971085</td>\n",
       "      <td>15B</td>\n",
       "      <td>15B_61</td>\n",
       "      <td>2</td>\n",
       "      <td>2976.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81</td>\n",
       "      <td>3.10</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5963272</td>\n",
       "      <td>7B</td>\n",
       "      <td>7B_93</td>\n",
       "      <td>2</td>\n",
       "      <td>4352.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352475</th>\n",
       "      <td>79</td>\n",
       "      <td>0.89</td>\n",
       "      <td>803</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>8584834</td>\n",
       "      <td>145</td>\n",
       "      <td>145_105</td>\n",
       "      <td>2</td>\n",
       "      <td>4289.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352476</th>\n",
       "      <td>80</td>\n",
       "      <td>1.79</td>\n",
       "      <td>803</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>8581813</td>\n",
       "      <td>40E</td>\n",
       "      <td>40E_91</td>\n",
       "      <td>2</td>\n",
       "      <td>1469.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352477</th>\n",
       "      <td>80</td>\n",
       "      <td>1.79</td>\n",
       "      <td>803</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>8586917</td>\n",
       "      <td>27B</td>\n",
       "      <td>27B_34</td>\n",
       "      <td>2</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352478</th>\n",
       "      <td>80</td>\n",
       "      <td>1.79</td>\n",
       "      <td>803</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>8582081</td>\n",
       "      <td>32</td>\n",
       "      <td>32_58</td>\n",
       "      <td>2</td>\n",
       "      <td>2095.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352479</th>\n",
       "      <td>80</td>\n",
       "      <td>1.79</td>\n",
       "      <td>803</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>8589189</td>\n",
       "      <td>40D</td>\n",
       "      <td>40D_103</td>\n",
       "      <td>2</td>\n",
       "      <td>2308.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>352480 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        humidity  wind_speed  weather_id  heavy_precip  HOUR   TRIPID LINEID  \\\n",
       "0             75        5.10         500             0     5  5962263     40   \n",
       "1             75        5.10         500             0     5  5963304     40   \n",
       "2             81        3.10         500             0     6  5958381    15B   \n",
       "3             81        3.10         500             0     6  5971085    15B   \n",
       "4             81        3.10         500             0     6  5963272     7B   \n",
       "...          ...         ...         ...           ...   ...      ...    ...   \n",
       "352475        79        0.89         803             0    21  8584834    145   \n",
       "352476        80        1.79         803             0    22  8581813    40E   \n",
       "352477        80        1.79         803             0    22  8586917    27B   \n",
       "352478        80        1.79         803             0    22  8582081     32   \n",
       "352479        80        1.79         803             0    22  8589189    40D   \n",
       "\n",
       "        ROUTEID  DIRECTION  TRIPTIME  WEEKDAY  MONTH  \n",
       "0         40_31          2    4574.0        1      1  \n",
       "1         40_31          2    4106.0        1      1  \n",
       "2        15B_61          2    3433.0        1      1  \n",
       "3        15B_61          2    2976.0        1      1  \n",
       "4         7B_93          2    4352.0        1      1  \n",
       "...         ...        ...       ...      ...    ...  \n",
       "352475  145_105          2    4289.0        0     12  \n",
       "352476   40E_91          2    1469.0        0     12  \n",
       "352477   27B_34          2    2388.0        0     12  \n",
       "352478    32_58          2    2095.0        0     12  \n",
       "352479  40D_103          2    2308.0        0     12  \n",
       "\n",
       "[352480 rows x 12 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dir_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dir_2 = df_dir_2.drop(columns=['heavy_precip','weather_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '102',\n",
       " '104',\n",
       " '11',\n",
       " '111',\n",
       " '114',\n",
       " '116',\n",
       " '118',\n",
       " '120',\n",
       " '122',\n",
       " '123',\n",
       " '13',\n",
       " '130',\n",
       " '14',\n",
       " '140',\n",
       " '142',\n",
       " '145',\n",
       " '14C',\n",
       " '15',\n",
       " '150',\n",
       " '151',\n",
       " '15A',\n",
       " '15B',\n",
       " '15D',\n",
       " '16',\n",
       " '161',\n",
       " '16C',\n",
       " '17',\n",
       " '17A',\n",
       " '18',\n",
       " '184',\n",
       " '185',\n",
       " '220',\n",
       " '236',\n",
       " '238',\n",
       " '239',\n",
       " '25',\n",
       " '25A',\n",
       " '25B',\n",
       " '25D',\n",
       " '25X',\n",
       " '26',\n",
       " '27',\n",
       " '270',\n",
       " '27A',\n",
       " '27B',\n",
       " '27X',\n",
       " '29A',\n",
       " '31',\n",
       " '31A',\n",
       " '31B',\n",
       " '31D',\n",
       " '32',\n",
       " '32X',\n",
       " '33',\n",
       " '33A',\n",
       " '33B',\n",
       " '33D',\n",
       " '33X',\n",
       " '37',\n",
       " '38',\n",
       " '38A',\n",
       " '38B',\n",
       " '38D',\n",
       " '39',\n",
       " '39A',\n",
       " '39X',\n",
       " '4',\n",
       " '40',\n",
       " '40B',\n",
       " '40D',\n",
       " '40E',\n",
       " '41',\n",
       " '41A',\n",
       " '41B',\n",
       " '41C',\n",
       " '41D',\n",
       " '41X',\n",
       " '42',\n",
       " '42D',\n",
       " '43',\n",
       " '44',\n",
       " '44B',\n",
       " '45A',\n",
       " '46A',\n",
       " '46E',\n",
       " '47',\n",
       " '49',\n",
       " '51D',\n",
       " '51X',\n",
       " '53',\n",
       " '54A',\n",
       " '56A',\n",
       " '59',\n",
       " '61',\n",
       " '63',\n",
       " '65',\n",
       " '65B',\n",
       " '66',\n",
       " '66A',\n",
       " '66B',\n",
       " '66X',\n",
       " '67',\n",
       " '67X',\n",
       " '68',\n",
       " '68A',\n",
       " '68X',\n",
       " '69',\n",
       " '69X',\n",
       " '7',\n",
       " '70',\n",
       " '70D',\n",
       " '75',\n",
       " '76',\n",
       " '76A',\n",
       " '77A',\n",
       " '77X',\n",
       " '79',\n",
       " '79A',\n",
       " '7A',\n",
       " '7B',\n",
       " '7D',\n",
       " '83',\n",
       " '83A',\n",
       " '84',\n",
       " '84A',\n",
       " '84X',\n",
       " '9']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_dir_2 = sorted(list(df_dir_2['LINEID'].unique()))\n",
    "lines_dir_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough values for line 41D\n"
     ]
    }
   ],
   "source": [
    "# Make dictionaries with keys for each stop with each train/test split value as its values.\n",
    "\n",
    "X_train_dict_2 = {}\n",
    "y_train_dict_2 = {}\n",
    "X_test_dict_2 ={}\n",
    "y_test_dict_2 = {}\n",
    "\n",
    "for line in lines_dir_2:\n",
    "    \n",
    "    df_line = df_dir_2[df_dir_2['LINEID']==line]\n",
    "    \n",
    "    #check for df with low values\n",
    "    if df_line.shape[0] < 3:\n",
    "        print('Not enough values for line', str(line))\n",
    "        lines_dir_2.remove(line)\n",
    "\n",
    "    else:\n",
    "        # randomly generate sequence based on dataframe index and set to be new index\n",
    "        df_line.set_index(np.random.permutation(df_line.index))\n",
    "        # sort the resulting random index\n",
    "        df_line.sort_index(inplace=True)\n",
    "\n",
    "        \n",
    "        # drop unneeded columns\n",
    "        df_line.drop(columns=['TRIPID', 'ROUTEID', 'DIRECTION','LINEID'], inplace=True)\n",
    "\n",
    "        X = df_line.drop([\"TRIPTIME\"],1)\n",
    "        y = pd.DataFrame(df_line['TRIPTIME'])\n",
    "\n",
    "        # do test train split\n",
    "        # Split the dataset into two datasets: 70% training and 30% test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=1)\n",
    "\n",
    "        X_train_dict_2[line] = X_train\n",
    "        y_train_dict_2[line] = y_train\n",
    "        X_test_dict_2[line] = X_test\n",
    "        y_test_dict_2[line] = y_test\n",
    "        \n",
    "        # need to reset the index to allow contatenation with predicted values otherwise not joining on same index...\n",
    "        X_train.reset_index(drop=True, inplace=True)\n",
    "        y_train.reset_index(drop=True, inplace=True)\n",
    "        X_test.reset_index(drop=True, inplace=True)\n",
    "        y_test.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict_2 = {}\n",
    "\n",
    "for line in lines_dir_2:\n",
    "    print(f'Line {line}')\n",
    "    \n",
    "    X_train_dict_2[line] = X_train\n",
    "    y_train_dict_2[line] = y_train\n",
    "    X_test_dict_2[line] = X_test\n",
    "    y_test_dict_2[line] = y_test\n",
    "\n",
    "    linReg = LinearRegression().fit(X_train, y_train)\n",
    "    \n",
    "    model_dict_2[line] = linReg\n",
    "\n",
    "    # code from https://stackoverflow.com/questions/11660605/how-to-overwrite-a-folder-if-it-already-exists-when-creating-it-with-makedirs\n",
    "\n",
    "    dir = f'/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/linearregression/picklefiles/line_{line}_model/dir2'\n",
    "    if os.path.exists(dir):\n",
    "        shutil.rmtree(dir)\n",
    "    os.makedirs(dir)\n",
    "    \n",
    "    filename = f'/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/linearregression/picklefiles/line_{line}_model/dir2/line_{line}_linreg.sav'\n",
    "    pickle.dump(linReg, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines_dir_2:  \n",
    "\n",
    "    # training data\n",
    "    X_train = X_train_dict_2[line]\n",
    "    y_train = y_train_dict_2[line]\n",
    "    linReg = model_dict_2[line]\n",
    "    \n",
    "    # test data\n",
    "    X_test = X_test_dict_2[line]\n",
    "    y_test = y_test_dict_2[line]\n",
    "    linReg = model_dict_2[line]\n",
    "            \n",
    "    print('Now modelling for line', str(line))\n",
    "    \n",
    "    linReg_predictions_train = list(linReg.predict(X_train))\n",
    "\n",
    "    # train metrics\n",
    "    train_mae = metrics.mean_absolute_error(y_train, linReg_predictions_train)\n",
    "    train_mape = metrics.mean_absolute_percentage_error(y_train, linReg_predictions_train)\n",
    "    train_mse = metrics.mean_squared_error(y_train, linReg_predictions_train)\n",
    "    train_rmse = metrics.mean_squared_error(y_train, linReg_predictions_train)**(0.5)\n",
    "    train_r2 = metrics.r2_score(y_train, linReg_predictions_train)\n",
    "\n",
    "    linReg_predictions_test = list(linReg.predict(X_test))\n",
    "\n",
    "    # test metrics\n",
    "    test_mae = metrics.mean_absolute_error(y_test, linReg_predictions_test)\n",
    "    test_mape = metrics.mean_absolute_percentage_error(y_test, linReg_predictions_test)\n",
    "    test_mse = metrics.mean_squared_error(y_test, linReg_predictions_test)\n",
    "    test_rmse = metrics.mean_squared_error(y_test, linReg_predictions_test)**(0.5)\n",
    "    test_r2 = metrics.r2_score(y_test, linReg_predictions_test)\n",
    "    \n",
    "    with open(f'/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/linearregression/picklefiles/line_{line}_model/dir2/line_{line}_linreg_metrics.csv', 'w') as file:\n",
    "        file.write(f'\\nTrain metrics for line {line}:'\n",
    "                f'\\nMAE: {metrics.mean_absolute_error(y_train, linReg_predictions_train)}' +\\\n",
    "                f'\\nMAPE: {metrics.mean_absolute_percentage_error(y_train, linReg_predictions_train)}'+\\\n",
    "                f'\\nMSE: {metrics.mean_squared_error(y_train, linReg_predictions_train)}'+\\\n",
    "                f'\\nRMSE: {metrics.mean_squared_error(y_train, linReg_predictions_train)**(0.5)}'+\\\n",
    "                f'\\nR2: {metrics.r2_score(y_train, linReg_predictions_train)}'+\\\n",
    "                f'\\nTest metrics for line {line}:'\n",
    "                f'\\nMAE: {metrics.mean_absolute_error(y_test, linReg_predictions_test)}' +\\\n",
    "                f'\\nMAPE: {metrics.mean_absolute_percentage_error(y_test, linReg_predictions_test)}'+\\\n",
    "                f'\\nMSE: {metrics.mean_squared_error(y_test, linReg_predictions_test)}'+\\\n",
    "                f'\\nRMSE: {metrics.mean_squared_error(y_test, linReg_predictions_test)**(0.5)}'+\\\n",
    "                f'\\nR2: {metrics.r2_score(y_test, linReg_predictions_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 1\n"
     ]
    }
   ],
   "source": [
    "rf_model_dict_2 = {}\n",
    "\n",
    "for line in lines_dir_2:\n",
    "    print(f'Line {line}')\n",
    "    \n",
    "    X_train_dict_2[line] = X_train\n",
    "    y_train_dict_2[line] = y_train\n",
    "    X_test_dict_2[line] = X_test\n",
    "    y_test_dict_2[line] = y_test\n",
    "\n",
    "    rfr = RandomForestRegressor(n_estimators=50, max_features='auto', oob_score=True, random_state=1)\n",
    "    result = rfr.fit(X_train, y_train)\n",
    "    rf_model_dict_2[line] = rfr\n",
    "\n",
    "    # code from https://stackoverflow.com/questions/11660605/how-to-overwrite-a-folder-if-it-already-exists-when-creating-it-with-makedirs\n",
    "\n",
    "    dir = f'/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/randomforest/picklefiles/line_{line}_model/dir2'\n",
    "    if os.path.exists(dir):\n",
    "        shutil.rmtree(dir)\n",
    "    os.makedirs(dir)\n",
    "    \n",
    "    filename = f'/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/randomforest/picklefiles/line_{line}_model/dir2/line_{line}_rfr.sav'\n",
    "    pickle.dump(rfr, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now modelling for line 1\n"
     ]
    }
   ],
   "source": [
    "for line in lines_dir_2:  \n",
    "\n",
    "    # training data\n",
    "    X_train = X_train_dict_2[line]\n",
    "    y_train = y_train_dict_2[line]\n",
    "    rfr = rf_model_dict_2[line]\n",
    "    \n",
    "    # test data\n",
    "    X_test = X_test_dict_2[line]\n",
    "    y_test = y_test_dict_2[line]\n",
    "    rfr = rf_model_dict_2[line]\n",
    "            \n",
    "    print('Now modelling for line', str(line))\n",
    "    \n",
    "    rfr_predictions_train = list(rfr.predict(X_train))\n",
    "    rfr_predictions_test = list(rfr.predict(X_test))\n",
    "\n",
    "    with open(f'/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/randomforest/picklefiles/line_{line}_model/dir2/line_{line}_rfr_metrics.csv', 'w') as file:\n",
    "        file.write(f'\\nMetrics for line {line}:'\n",
    "                f'\\nMAE: {metrics.mean_absolute_error(y_train, rfr_predictions_train)}' +\\\n",
    "                f'\\nMAPE: {metrics.mean_absolute_percentage_error(y_train, rfr_predictions_train)}'+\\\n",
    "                f'\\nMSE: {metrics.mean_squared_error(y_train, rfr_predictions_train)}'+\\\n",
    "                f'\\nRMSE: {metrics.mean_squared_error(y_train, rfr_predictions_train)**(0.5)}'+\\\n",
    "                f'\\nR2: {metrics.r2_score(y_train, rfr_predictions_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOUR</td>\n",
       "      <td>0.578939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WEEKDAY</td>\n",
       "      <td>0.134704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wind_speed</td>\n",
       "      <td>0.103197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>humidity</td>\n",
       "      <td>0.096059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MONTH</td>\n",
       "      <td>0.087101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  importance\n",
       "2        HOUR    0.578939\n",
       "3     WEEKDAY    0.134704\n",
       "1  wind_speed    0.103197\n",
       "0    humidity    0.096059\n",
       "4       MONTH    0.087101"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = pd.DataFrame({'feature': X_train.columns, 'importance':rfr.feature_importances_})\n",
    "importance.sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model currently at 0.82\n",
    "* drop heavy_precip (0.02)\n",
    "\n",
    "model currently at 0.828\n",
    "* drop weather_id (0.046414)\n",
    "\n",
    "model currently at 0.827"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7699efb4af24be428a0b5648dfa7aba129b905e3165e555843cf88f6106e2e55"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('rp22')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
