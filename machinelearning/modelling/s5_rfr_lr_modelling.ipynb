{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pickle\n",
    "import joblib\n",
    "import os \n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "Code adapted from https://github.com/jamie-reynolds-UCD/UCD-Dublin-Bus-App-Team9/blob/main/data/General_Files_Linreg/general_LinRegModelling.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in files for direction 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dir_1 = pd.read_csv(\n",
    "    '/Users/rebeccadillon/git/dublin-bus-team-5/data/cleaned/feature_pairwise_cleaned_dir1.csv')\n",
    "df_dir_2 = pd.read_csv(\n",
    "    '/Users/rebeccadillon/git/dublin-bus-team-5/data/cleaned/feature_pairwise_cleaned_dir2.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print some descriptors of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The shape of the direction 1 dataframe is:\", df_dir_1.shape)\n",
    "print(\"The shape of the direction 2 dataframe is:\", df_dir_2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The datatypes in the direction 1 dataframe is:\")\n",
    "print(df_dir_1.dtypes)\n",
    "print(\"The datatypes in the direction 2 dataframe is:\")\n",
    "print(df_dir_2.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The number of null values in the direction 1 dataframe is: \",\n",
    "      str(df_dir_1.isna().sum()))\n",
    "print(\"The number of null values in the direction 2 dataframe is: \",\n",
    "      str(df_dir_2.isna().sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing the above column names in each dataframe. Column names should be consistent throughout both direction 1 and 2 dataframes. This is to ensure both dataframes contain the same columns for simplicity when combining with the front-end for feature input.\n",
    "\n",
    "We can see above that direction 1 differs to direction 2 where it has the column temp. I will remove temp from direction 1 so that both dataframes contain the same features. This will make connecting the model with the frontend to fetch the input variables much easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dir_1 = df_dir_1.drop(columns=['temp'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The columns in direction 1 dataframe are:\")\n",
    "print(df_dir_1.columns)\n",
    "\n",
    "print(\"The columns in direction 2 dataframe are:\")\n",
    "print(df_dir_2.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dir_1.to_csv(\n",
    "    '/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/modelling_ready_dir1.csv', index=False)\n",
    "df_dir_2.to_csv(\n",
    "    '/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/modelling_ready_dir2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direction 1\n",
    "Remembering from <i>s4_feature_pairwise_interactions.ipynb</i> the following:<br>\n",
    "* Categorical features with medium information gain are 'MONTH', 'heavy_precip' and 'weather_id'\n",
    "* Categorical features with high information gain are 'HOUR' and 'WEEKDAY'\n",
    "* Categorical features with low information gain were dropped.\n",
    "<br>\n",
    "\n",
    "When tried first on a linear regression model, we were receiving low accuracy with $r^2$ values below 0.2. We then switched to a Random Forest Regressor (RFR) model, which was proving to be a better fit for the data.\n",
    "\n",
    "We began the RFR with all features (both medium and high information gain), and omitted features step by step in order to find the highest performing model that would give the most accuracy. Below is the code for this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Test-train-split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns negatively impacting the model's performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dir_1 = pd.read_csv(\n",
    "    '/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/modelling_ready_dir1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>humidity</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>LINEID</th>\n",
       "      <th>PLANNEDTIME_DEP</th>\n",
       "      <th>TRIPTIME</th>\n",
       "      <th>WEEKDAY</th>\n",
       "      <th>MONTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>5.10</td>\n",
       "      <td>65</td>\n",
       "      <td>19800.0</td>\n",
       "      <td>4425.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81</td>\n",
       "      <td>3.10</td>\n",
       "      <td>14</td>\n",
       "      <td>23400.0</td>\n",
       "      <td>4281.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81</td>\n",
       "      <td>3.10</td>\n",
       "      <td>39</td>\n",
       "      <td>22920.0</td>\n",
       "      <td>3758.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81</td>\n",
       "      <td>3.10</td>\n",
       "      <td>140</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>2732.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>81</td>\n",
       "      <td>3.10</td>\n",
       "      <td>123</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>2658.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354150</th>\n",
       "      <td>79</td>\n",
       "      <td>0.89</td>\n",
       "      <td>25B</td>\n",
       "      <td>78420.0</td>\n",
       "      <td>2559.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354151</th>\n",
       "      <td>80</td>\n",
       "      <td>1.79</td>\n",
       "      <td>130</td>\n",
       "      <td>79200.0</td>\n",
       "      <td>1734.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354152</th>\n",
       "      <td>80</td>\n",
       "      <td>1.79</td>\n",
       "      <td>27B</td>\n",
       "      <td>78900.0</td>\n",
       "      <td>2108.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354153</th>\n",
       "      <td>80</td>\n",
       "      <td>1.79</td>\n",
       "      <td>120</td>\n",
       "      <td>79200.0</td>\n",
       "      <td>1327.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354154</th>\n",
       "      <td>80</td>\n",
       "      <td>1.79</td>\n",
       "      <td>25A</td>\n",
       "      <td>79320.0</td>\n",
       "      <td>2745.0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>354155 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        humidity  wind_speed LINEID  PLANNEDTIME_DEP  TRIPTIME  WEEKDAY  MONTH\n",
       "0             75        5.10     65          19800.0    4425.0        1      1\n",
       "1             81        3.10     14          23400.0    4281.0        1      1\n",
       "2             81        3.10     39          22920.0    3758.0        1      1\n",
       "3             81        3.10    140          24000.0    2732.0        1      1\n",
       "4             81        3.10    123          24000.0    2658.0        1      1\n",
       "...          ...         ...    ...              ...       ...      ...    ...\n",
       "354150        79        0.89    25B          78420.0    2559.0        0     12\n",
       "354151        80        1.79    130          79200.0    1734.0        0     12\n",
       "354152        80        1.79    27B          78900.0    2108.0        0     12\n",
       "354153        80        1.79    120          79200.0    1327.0        0     12\n",
       "354154        80        1.79    25A          79320.0    2745.0        0     12\n",
       "\n",
       "[354155 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dir_1 = df_dir_1.drop(columns=['heavy_precip', 'weather_id', 'HOUR'])\n",
    "df_dir_1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print a list of the unique line ids in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '102',\n",
       " '104',\n",
       " '11',\n",
       " '111',\n",
       " '114',\n",
       " '116',\n",
       " '120',\n",
       " '122',\n",
       " '123',\n",
       " '13',\n",
       " '130',\n",
       " '14',\n",
       " '140',\n",
       " '142',\n",
       " '145',\n",
       " '14C',\n",
       " '15',\n",
       " '150',\n",
       " '151',\n",
       " '15A',\n",
       " '15B',\n",
       " '15D',\n",
       " '16',\n",
       " '161',\n",
       " '16C',\n",
       " '16D',\n",
       " '17',\n",
       " '17A',\n",
       " '18',\n",
       " '184',\n",
       " '185',\n",
       " '220',\n",
       " '236',\n",
       " '238',\n",
       " '239',\n",
       " '25',\n",
       " '25A',\n",
       " '25B',\n",
       " '25D',\n",
       " '25X',\n",
       " '26',\n",
       " '27',\n",
       " '270',\n",
       " '27A',\n",
       " '27B',\n",
       " '27X',\n",
       " '29A',\n",
       " '31',\n",
       " '31A',\n",
       " '31B',\n",
       " '31D',\n",
       " '32',\n",
       " '32X',\n",
       " '33',\n",
       " '33A',\n",
       " '33B',\n",
       " '33D',\n",
       " '33E',\n",
       " '33X',\n",
       " '37',\n",
       " '38',\n",
       " '38A',\n",
       " '38B',\n",
       " '38D',\n",
       " '39',\n",
       " '39A',\n",
       " '39X',\n",
       " '4',\n",
       " '40',\n",
       " '40B',\n",
       " '40D',\n",
       " '40E',\n",
       " '41',\n",
       " '41B',\n",
       " '41C',\n",
       " '41D',\n",
       " '41X',\n",
       " '42',\n",
       " '42D',\n",
       " '43',\n",
       " '44',\n",
       " '44B',\n",
       " '45A',\n",
       " '46A',\n",
       " '47',\n",
       " '49',\n",
       " '51D',\n",
       " '53',\n",
       " '54A',\n",
       " '56A',\n",
       " '59',\n",
       " '61',\n",
       " '63',\n",
       " '65',\n",
       " '65B',\n",
       " '66',\n",
       " '66A',\n",
       " '66B',\n",
       " '66X',\n",
       " '67',\n",
       " '67X',\n",
       " '68',\n",
       " '68A',\n",
       " '69',\n",
       " '69X',\n",
       " '7',\n",
       " '70',\n",
       " '70D',\n",
       " '75',\n",
       " '76',\n",
       " '76A',\n",
       " '77A',\n",
       " '79',\n",
       " '79A',\n",
       " '7A',\n",
       " '7B',\n",
       " '7D',\n",
       " '83',\n",
       " '83A',\n",
       " '84',\n",
       " '84A',\n",
       " '84X',\n",
       " '9']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_dir_1 = sorted(list(df_dir_1['LINEID'].unique()))\n",
    "lines_dir_1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up test-train-split for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough values for line 41D\n"
     ]
    }
   ],
   "source": [
    "# Make dictionaries with keys for each stop with each train/test split value as its values.\n",
    "\n",
    "X_train_dict_1 = {}\n",
    "y_train_dict_1 = {}\n",
    "X_test_dict_1 = {}\n",
    "y_test_dict_1 = {}\n",
    "\n",
    "for line in lines_dir_1:\n",
    "\n",
    "    # dataframe containing only rows with current lineid\n",
    "    df_line = df_dir_1[df_dir_1['LINEID'] == line]\n",
    "\n",
    "    # check for df with low values (where accurate predictions will not be possible as any one value will have too much influence on the overall model outcome)\n",
    "    if df_line.shape[0] < 3:\n",
    "        print('Not enough values for line', str(line))\n",
    "        lines_dir_1.remove(line)\n",
    "\n",
    "    else:\n",
    "        # shuffle data frame code from 'sample_solution_COMP47350_Task2_PredictiveModeling_Evaluation_CreditRiskPrediction.ipynb'\n",
    "        # randomly generate sequence based on dataframe index and set to be new index\n",
    "        df_line.set_index(np.random.permutation(df_line.index))\n",
    "        # sort the resulting random index\n",
    "        df_line.sort_index(inplace=True)\n",
    "\n",
    "        # drop unneeded columns\n",
    "        df_line.drop(columns=['LINEID'], inplace=True)\n",
    "\n",
    "        X = df_line.drop(columns=[\"TRIPTIME\"], axis=1)\n",
    "        y = pd.DataFrame(df_line['TRIPTIME'])\n",
    "\n",
    "        # do test train split\n",
    "        # Split the dataset into two datasets, 70% training and 30% test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "        X_train_dict_1[line] = X_train\n",
    "        y_train_dict_1[line] = y_train\n",
    "        X_test_dict_1[line] = X_test\n",
    "        y_test_dict_1[line] = y_test\n",
    "\n",
    "        # reset index \n",
    "        X_train.reset_index(drop=True, inplace=True)\n",
    "        y_train.reset_index(drop=True, inplace=True)\n",
    "        X_test.reset_index(drop=True, inplace=True)\n",
    "        y_test.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the only line with less than 3 rows is 41D. We will therefore omit this line from modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a pickle file containing the prediction model for each line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict_1 = {}\n",
    "\n",
    "for line in lines_dir_1:\n",
    "    print(f'Line {line}')\n",
    "\n",
    "    X_train_dict_1[line] = X_train\n",
    "    y_train_dict_1[line] = y_train\n",
    "    X_test_dict_1[line] = X_test\n",
    "    y_test_dict_1[line] = y_test\n",
    "\n",
    "    linReg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "    model_dict_1[line] = linReg\n",
    "\n",
    "    # code from https://stackoverflow.com/questions/11660605/how-to-overwrite-a-folder-if-it-already-exists-when-creating-it-with-makedirs\n",
    "\n",
    "    dir = f'/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/linearregression/picklefiles/line_{line}_model/dir1'\n",
    "    if os.path.exists(dir):\n",
    "        shutil.rmtree(dir)\n",
    "    os.makedirs(dir)\n",
    "\n",
    "    filename = f'/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/linearregression/picklefiles/line_{line}_model/dir1/line_{line}_linreg.sav'\n",
    "    pickle.dump(linReg, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print some metrics evaluating the prediciton models performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines_dir_1:\n",
    "\n",
    "    # training data\n",
    "    X_train = X_train_dict_1[line]\n",
    "    y_train = y_train_dict_1[line]\n",
    "    linReg = model_dict_1[line]\n",
    "\n",
    "    # test data\n",
    "    X_test = X_test_dict_1[line]\n",
    "    y_test = y_test_dict_1[line]\n",
    "    linReg = model_dict_1[line]\n",
    "\n",
    "    print('Modelling for line', str(line))\n",
    "\n",
    "    linReg_predictions_train = list(linReg.predict(X_train))\n",
    "\n",
    "    # train metrics\n",
    "    train_mae = metrics.mean_absolute_error(y_train, linReg_predictions_train)\n",
    "    train_mape = metrics.mean_absolute_percentage_error(\n",
    "        y_train, linReg_predictions_train)\n",
    "    train_mse = metrics.mean_squared_error(y_train, linReg_predictions_train)\n",
    "    train_rmse = metrics.mean_squared_error(\n",
    "        y_train, linReg_predictions_train)**(0.5)\n",
    "    train_r2 = metrics.r2_score(y_train, linReg_predictions_train)\n",
    "\n",
    "    linReg_predictions_test = list(linReg.predict(X_test))\n",
    "\n",
    "    # test metrics\n",
    "    test_mae = metrics.mean_absolute_error(y_test, linReg_predictions_test)\n",
    "    test_mape = metrics.mean_absolute_percentage_error(\n",
    "        y_test, linReg_predictions_test)\n",
    "    test_mse = metrics.mean_squared_error(y_test, linReg_predictions_test)\n",
    "    test_rmse = metrics.mean_squared_error(\n",
    "        y_test, linReg_predictions_test)**(0.5)\n",
    "    test_r2 = metrics.r2_score(y_test, linReg_predictions_test)\n",
    "\n",
    "    with open(f'/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/linearregression/picklefiles/line_{line}_model/dir1/line_{line}_linreg_metrics.csv', 'w') as file:\n",
    "        file.write(f'\\nTrain metrics for line {line}:'\n",
    "                   f'\\nMAE: {train_mae}' +\n",
    "                   f'\\nMAPE: {train_mape}' +\n",
    "                   f'\\nMSE: {train_mse}' +\n",
    "                   f'\\nRMSE: {train_rmse**(0.5)}' +\n",
    "                   f'\\nR2: {train_r2}' +\n",
    "                   f'\\nTest metrics for line {line}:'\n",
    "                   f'\\nMAE: {test_mae}' +\n",
    "                   f'\\nMAPE: {test_mape}' +\n",
    "                   f'\\nMSE: {test_mse}' +\n",
    "                   f'\\nRMSE: {test_rmse**(0.5)}' +\n",
    "                   f'\\nR2: {test_r2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Random Forest\n",
    "### 1.3.1 Create the model\n",
    "The random forest model works on the same test-train-splits as above. This next cell creates a prediction model for each line and dumps the model into a pickle file. Improved through https://www.keboola.com/blog/random-forest-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 1\n",
      "Line 102\n",
      "Line 104\n",
      "Line 11\n",
      "Line 111\n",
      "Line 114\n",
      "Line 116\n",
      "Line 120\n",
      "Line 122\n",
      "Line 123\n",
      "Line 13\n",
      "Line 130\n",
      "Line 14\n",
      "Line 140\n",
      "Line 142\n",
      "Line 145\n",
      "Line 14C\n",
      "Line 15\n",
      "Line 150\n",
      "Line 151\n",
      "Line 15A\n",
      "Line 15B\n",
      "Line 15D\n",
      "Line 16\n",
      "Line 161\n",
      "Line 16C\n",
      "Line 16D\n",
      "Line 17\n",
      "Line 17A\n",
      "Line 18\n",
      "Line 184\n",
      "Line 185\n",
      "Line 220\n",
      "Line 236\n",
      "Line 238\n",
      "Line 239\n",
      "Line 25\n",
      "Line 25A\n",
      "Line 25B\n",
      "Line 25D\n",
      "Line 25X\n",
      "Line 26\n",
      "Line 27\n",
      "Line 270\n",
      "Line 27A\n",
      "Line 27B\n",
      "Line 27X\n",
      "Line 29A\n",
      "Line 31\n",
      "Line 31A\n",
      "Line 31B\n",
      "Line 31D\n",
      "Line 32\n",
      "Line 32X\n",
      "Line 33\n",
      "Line 33A\n",
      "Line 33B\n",
      "Line 33D\n",
      "Line 33E\n",
      "Line 33X\n",
      "Line 37\n",
      "Line 38\n",
      "Line 38A\n",
      "Line 38B\n",
      "Line 38D\n",
      "Line 39\n",
      "Line 39A\n",
      "Line 39X\n",
      "Line 4\n",
      "Line 40\n",
      "Line 40B\n",
      "Line 40D\n",
      "Line 40E\n",
      "Line 41\n",
      "Line 41B\n",
      "Line 41C\n",
      "Line 41X\n",
      "Line 42\n",
      "Line 42D\n",
      "Line 43\n",
      "Line 44\n",
      "Line 44B\n",
      "Line 45A\n",
      "Line 46A\n",
      "Line 47\n",
      "Line 49\n",
      "Line 51D\n",
      "Line 53\n",
      "Line 54A\n",
      "Line 56A\n",
      "Line 59\n",
      "Line 61\n",
      "Line 63\n",
      "Line 65\n",
      "Line 65B\n",
      "Line 66\n",
      "Line 66A\n",
      "Line 66B\n",
      "Line 66X\n",
      "Line 67\n",
      "Line 67X\n",
      "Line 68\n",
      "Line 68A\n",
      "Line 69\n",
      "Line 69X\n",
      "Line 7\n",
      "Line 70\n",
      "Line 70D\n",
      "Line 75\n",
      "Line 76\n",
      "Line 76A\n",
      "Line 77A\n",
      "Line 79\n",
      "Line 79A\n",
      "Line 7A\n",
      "Line 7B\n",
      "Line 7D\n",
      "Line 83\n",
      "Line 83A\n",
      "Line 84\n",
      "Line 84A\n",
      "Line 84X\n",
      "Line 9\n"
     ]
    }
   ],
   "source": [
    "rf_model_dict_1 = {}\n",
    "\n",
    "for line in lines_dir_1:\n",
    "    print(f'Line {line}')\n",
    "\n",
    "    X_train_dict_1[line] = X_train\n",
    "    y_train_dict_1[line] = y_train\n",
    "    X_test_dict_1[line] = X_test\n",
    "    y_test_dict_1[line] = y_test\n",
    "\n",
    "    rfr = RandomForestRegressor(oob_score=True, random_state=1, max_depth=20, n_estimators=20)\n",
    "    result = rfr.fit(X_train, y_train)\n",
    "    rf_model_dict_1[line] = rfr\n",
    "\n",
    "    # code from https://stackoverflow.com/questions/11660605/how-to-overwrite-a-folder-if-it-already-exists-when-creating-it-with-makedirs\n",
    "\n",
    "    dir = f'/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/randomforest/joblibfiles/line_{line}_model/dir1'\n",
    "    if os.path.exists(dir):\n",
    "        shutil.rmtree(dir)\n",
    "    os.makedirs(dir)\n",
    "\n",
    "    # save the model to a joblib file\n",
    "    filename = f'/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/randomforest/joblibfiles/line_{line}_model/dir1/line_{line}_rfr.joblib'\n",
    "    joblib.dump(rfr, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print metrics for each line into accompanying files outling the prediction model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelling for line 1\n",
      "Modelling for line 102\n",
      "Modelling for line 104\n",
      "Modelling for line 11\n",
      "Modelling for line 111\n",
      "Modelling for line 114\n",
      "Modelling for line 116\n",
      "Modelling for line 120\n",
      "Modelling for line 122\n",
      "Modelling for line 123\n",
      "Modelling for line 13\n",
      "Modelling for line 130\n",
      "Modelling for line 14\n",
      "Modelling for line 140\n",
      "Modelling for line 142\n",
      "Modelling for line 145\n",
      "Modelling for line 14C\n",
      "Modelling for line 15\n",
      "Modelling for line 150\n",
      "Modelling for line 151\n",
      "Modelling for line 15A\n",
      "Modelling for line 15B\n",
      "Modelling for line 15D\n",
      "Modelling for line 16\n",
      "Modelling for line 161\n",
      "Modelling for line 16C\n",
      "Modelling for line 16D\n",
      "Modelling for line 17\n",
      "Modelling for line 17A\n",
      "Modelling for line 18\n",
      "Modelling for line 184\n",
      "Modelling for line 185\n",
      "Modelling for line 220\n",
      "Modelling for line 236\n",
      "Modelling for line 238\n",
      "Modelling for line 239\n",
      "Modelling for line 25\n",
      "Modelling for line 25A\n",
      "Modelling for line 25B\n",
      "Modelling for line 25D\n",
      "Modelling for line 25X\n",
      "Modelling for line 26\n",
      "Modelling for line 27\n",
      "Modelling for line 270\n",
      "Modelling for line 27A\n",
      "Modelling for line 27B\n",
      "Modelling for line 27X\n",
      "Modelling for line 29A\n",
      "Modelling for line 31\n",
      "Modelling for line 31A\n",
      "Modelling for line 31B\n",
      "Modelling for line 31D\n",
      "Modelling for line 32\n",
      "Modelling for line 32X\n",
      "Modelling for line 33\n",
      "Modelling for line 33A\n",
      "Modelling for line 33B\n",
      "Modelling for line 33D\n",
      "Modelling for line 33E\n",
      "Modelling for line 33X\n",
      "Modelling for line 37\n",
      "Modelling for line 38\n",
      "Modelling for line 38A\n",
      "Modelling for line 38B\n",
      "Modelling for line 38D\n",
      "Modelling for line 39\n",
      "Modelling for line 39A\n",
      "Modelling for line 39X\n",
      "Modelling for line 4\n",
      "Modelling for line 40\n",
      "Modelling for line 40B\n",
      "Modelling for line 40D\n",
      "Modelling for line 40E\n",
      "Modelling for line 41\n",
      "Modelling for line 41B\n",
      "Modelling for line 41C\n",
      "Modelling for line 41X\n",
      "Modelling for line 42\n",
      "Modelling for line 42D\n",
      "Modelling for line 43\n",
      "Modelling for line 44\n",
      "Modelling for line 44B\n",
      "Modelling for line 45A\n",
      "Modelling for line 46A\n",
      "Modelling for line 47\n",
      "Modelling for line 49\n",
      "Modelling for line 51D\n",
      "Modelling for line 53\n",
      "Modelling for line 54A\n",
      "Modelling for line 56A\n",
      "Modelling for line 59\n",
      "Modelling for line 61\n",
      "Modelling for line 63\n",
      "Modelling for line 65\n",
      "Modelling for line 65B\n",
      "Modelling for line 66\n",
      "Modelling for line 66A\n",
      "Modelling for line 66B\n",
      "Modelling for line 66X\n",
      "Modelling for line 67\n",
      "Modelling for line 67X\n",
      "Modelling for line 68\n",
      "Modelling for line 68A\n",
      "Modelling for line 69\n",
      "Modelling for line 69X\n",
      "Modelling for line 7\n",
      "Modelling for line 70\n",
      "Modelling for line 70D\n",
      "Modelling for line 75\n",
      "Modelling for line 76\n",
      "Modelling for line 76A\n",
      "Modelling for line 77A\n",
      "Modelling for line 79\n",
      "Modelling for line 79A\n",
      "Modelling for line 7A\n",
      "Modelling for line 7B\n",
      "Modelling for line 7D\n",
      "Modelling for line 83\n",
      "Modelling for line 83A\n",
      "Modelling for line 84\n",
      "Modelling for line 84A\n",
      "Modelling for line 84X\n",
      "Modelling for line 9\n"
     ]
    }
   ],
   "source": [
    "# sum for averages\n",
    "train_mae_sum = 0\n",
    "train_mape_sum = 0\n",
    "train_mse_sum = 0\n",
    "train_r2_sum = 0\n",
    "\n",
    "test_mae_sum = 0\n",
    "test_mape_sum = 0\n",
    "test_mse_sum = 0\n",
    "test_r2_sum = 0\n",
    "\n",
    "for line in lines_dir_1:  \n",
    "\n",
    "    # training data\n",
    "    X_train = X_train_dict_1[line]\n",
    "    y_train = y_train_dict_1[line]\n",
    "    rfr = rf_model_dict_1[line]\n",
    "    \n",
    "    # test data\n",
    "    X_test = X_test_dict_1[line]\n",
    "    y_test = y_test_dict_1[line]\n",
    "    rfr = rf_model_dict_1[line]\n",
    "            \n",
    "    print('Modelling for line', str(line))\n",
    "    \n",
    "    rfr_predictions_train = list(rfr.predict(X_train))\n",
    "    rfr_predictions_test = list(rfr.predict(X_test))\n",
    "\n",
    "    # choice of metrics from https://medium.com/analytics-vidhya/evaluating-a-random-forest-model-9d165595ad56 and\n",
    "    # https://towardsdatascience.com/random-forest-regression-5f605132d19d\n",
    "    train_mae = metrics.mean_absolute_error(y_train, rfr_predictions_train) \n",
    "    train_mape = metrics.mean_absolute_percentage_error(y_train, rfr_predictions_train) # should be as close to 0 as possible (percentage error)\n",
    "    train_mse = metrics.mean_squared_error(y_train, rfr_predictions_train) # as close to 0 as possible\n",
    "    train_r2 = metrics.r2_score(y_train, rfr_predictions_train) #close to 1\n",
    "    \n",
    "    test_mae = metrics.mean_absolute_error(y_test, rfr_predictions_test) \n",
    "    test_mape = metrics.mean_absolute_percentage_error(y_test, rfr_predictions_test) \n",
    "    test_mse = metrics.mean_squared_error(y_test, rfr_predictions_test)\n",
    "    test_r2 = metrics.r2_score(y_test, rfr_predictions_test)\n",
    "\n",
    "\n",
    "    with open(f'/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/randomforest/joblibfiles/line_{line}_model/dir1/line_{line}_rfr_metrics.csv', 'w') as file:\n",
    "        file.write(f'\\nTrain metrics for line {line}:'\n",
    "                f'\\nMAE: {train_mae}'+\\\n",
    "                f'\\nMAPE: {train_mape}'+\\\n",
    "                f'\\nMSE: {train_mse}'+\\\n",
    "                f'\\nR2: {train_r2}' +\\\n",
    "                f'\\nTest metrics for line {line}:'\n",
    "                f'\\nMAE: {test_mae}'+\\\n",
    "                f'\\nMAPE: {test_mape}'+\\\n",
    "                f'\\nMSE: {test_mse}'+\\\n",
    "                f'\\nR2: {test_r2}')\n",
    "\n",
    "    # sum for averages\n",
    "    train_mae_sum +=train_mae\n",
    "    train_mape_sum +=train_mape\n",
    "    train_mse_sum +=train_mse\n",
    "    train_r2_sum +=train_r2\n",
    "\n",
    "    test_mae_sum += test_mae\n",
    "    test_mape_sum += test_mape\n",
    "    test_mse_sum += test_mse\n",
    "    test_r2_sum += test_r2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the average score for each metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Train metrics=============\n",
      "Mean MAE: 148.17262075230093\n",
      "Mean MAPE: 0.03155302514462164\n",
      "Mean MSE: 40779.36629184613\n",
      "Mean R2: 0.948731359068958\n",
      "============Test metrics=============\n",
      "Mean MAE: 356.5623111972214\n",
      "Mean MAPE: 0.07721799238506949\n",
      "Mean MSE: 213644.10060967883\n",
      "Mean R2: 0.74598056287167\n"
     ]
    }
   ],
   "source": [
    "print(\"============Train metrics=============\")\n",
    "print(\"Mean MAE:\", str(train_mae_sum/len(lines_dir_1)))\n",
    "print(\"Mean MAPE:\", str(train_mape_sum/len(lines_dir_1)))\n",
    "print(\"Mean MSE:\", str(train_mse_sum/len(lines_dir_1)))\n",
    "print(\"Mean R2:\", str(train_r2_sum/len(lines_dir_1)))\n",
    "\n",
    "print(\"============Test metrics=============\")\n",
    "print(\"Mean MAE:\", str(test_mae_sum/len(lines_dir_1)))\n",
    "print(\"Mean MAPE:\", str(test_mape_sum/len(lines_dir_1)))\n",
    "print(\"Mean MSE:\", str(test_mse_sum/len(lines_dir_1)))\n",
    "print(\"Mean R2:\", str(test_r2_sum/len(lines_dir_1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the order of the most influential features on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = pd.DataFrame(\n",
    "    {'feature': X_train.columns, 'importance': rfr.feature_importances_})\n",
    "importance.sort_values('importance', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|FEATURE|IMPORTANCE|%|\n",
    "|-------|----------|-|\n",
    "|PLANNEDTIME_DEP|0.601|60.1%|\n",
    "|WEEKDAY|0.164|16.4%\n",
    "|wind_speed|0.067|6.7%|\n",
    "|humidity|0.063|6.3%|\n",
    "|MONTH|0.056|5.6%|\n",
    "|weather_id|0.034|3.4%|\n",
    "|HOUR|0.014|1.4%|\n",
    "|heavy_precip|0.001|0.1%|\n",
    "\n",
    "- The above result shows that PLANNEDTIME_DEP is the most influential on the model at 60%. This means that PLANNEDTIME_DEP accounts for 60% of the variation in TRIPTIME.\n",
    "\n",
    "- Initial mean test MAE is 350.17 or 5 minutes 50 seconds\n",
    "- Initial mean test MAPE is 0.076 or 7.6%\n",
    "\n",
    "**Step 1**\n",
    "- Drop heavy_precip from the dataframe (less than 1% importance with 8 features)\n",
    "    - Mean test MAE now 349.9 or 5 minutes and 50 seconds\n",
    "    - Mean test MAPE now 0.076 or 7.6%\n",
    "- MAE has decreased showing that the model has improved.\n",
    "\n",
    "\n",
    "**Step 2**\n",
    "- Drop HOUR from the dataframe (1.5% importance with 7 features)\n",
    "    - Mean test MAE now 350.4 or 5 minutes and 50 seconds\n",
    "    - Mean test MAPE now 0.0759 or 7.6%\n",
    "- MAE has increased marginally. To keep the same features in both sets of models (direction 1 and direction 2), I will continue dropping features from this model as there is a more noticable difference in the effect of feature inclusion on direction 2's models.\n",
    "\n",
    "\n",
    "**Step 3**\n",
    "- Drop weather_id from the dataframe (3.5% importance with 6 features)\n",
    "    - Mean test MAE now 349.35 or 5 minutes and 49 seconds\n",
    "    - Mean test MAPE now 0.0757 or 7.6%\n",
    "- Both metrics have improved.\n",
    "\n",
    "We will stop ammending the models now as the same features are present in both sets of models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_RandomForest_DF(X, y, depth=None, estimators=100):\n",
    "    \"\"\"Function to perform cross validation and store results \n",
    "    in dataframe. Cross validation looks at accuracy, precision, \n",
    "    recall, f1. Returns a dataframe with results\"\"\"\n",
    "\n",
    "    # store results in dict\n",
    "    RandomForestResults = {}\n",
    "    # metrics to test against\n",
    "    test_metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "    for metric in test_metrics:\n",
    "        # generate test results\n",
    "        result = cross_val_score(RandomForestRegressor(\n",
    "            n_estimators=estimators, max_features='auto', random_state=1, max_depth=depth), X, y, scoring=metric, cv=10)\n",
    "        # store result in dict\n",
    "        RandomForestResults[metric] = result.mean()\n",
    "\n",
    "    # create dataframe with results\n",
    "    RandomForestDF = pd.DataFrame.from_dict(\n",
    "        RandomForestResults, orient='index', columns=['Random_Forests'])\n",
    "\n",
    "    return RandomForestDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestDF = cross_val_RandomForest_DF(X, y)\n",
    "print(f\"Mean results from 10 fold cross validation are:\")\n",
    "RandomForestDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the out-of-bag classification accuracy\n",
    "rfr.oob_score_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbour Regression\n",
    "We have already determined the Random Forest Regressor to have a mean actual error score of 349.35 seconds and a mean actual percentage error score of 7.6%. To determine if our model can improve, we will now use a K Nearest Neighbour modelling algorithm on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model_dict_1 = {}\n",
    "\n",
    "for line in lines_dir_1:\n",
    "    print(f'Line {line}')\n",
    "\n",
    "    X_train_dict_1[line] = X_train\n",
    "    y_train_dict_1[line] = y_train\n",
    "    X_test_dict_1[line] = X_test\n",
    "    y_test_dict_1[line] = y_test\n",
    "\n",
    "    nbrs = KNeighborsRegressor(n_neighbors=7).fit(X_train, y_train)\n",
    "\n",
    "    nb_model_dict_1[line] = nbrs\n",
    "\n",
    "    # code from https://stackoverflow.com/questions/11660605/how-to-overwrite-a-folder-if-it-already-exists-when-creating-it-with-makedirs\n",
    "\n",
    "    dir = f'/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/knn/picklefiles/line_{line}_model/dir1'\n",
    "    if os.path.exists(dir):\n",
    "        shutil.rmtree(dir)\n",
    "    os.makedirs(dir)\n",
    "\n",
    "    filename = f'/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/knn/picklefiles/line_{line}_model/dir1/line_{line}_nb.sav'\n",
    "    pickle.dump(nbrs, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_train_score = 0\n",
    "sum_test_score = 0\n",
    "\n",
    "for line in lines_dir_1:\n",
    "\n",
    "    # training data\n",
    "    X_train = X_train_dict_1[line]\n",
    "    y_train = y_train_dict_1[line]\n",
    "    # test data\n",
    "    X_test = X_test_dict_1[line]\n",
    "    y_test = y_test_dict_1[line]\n",
    "    nbrs = nb_model_dict_1[line]\n",
    "\n",
    "    print('Modelling for line', str(line))\n",
    "\n",
    "    nb_predictions_train = list(nbrs.predict(X_train))\n",
    "    nb_predictions_test = list(nbrs.predict(X_test))\n",
    "    # choice of metrics from https://medium.com/analytics-vidhya/evaluating-a-random-forest-model-9d165595ad56 and\n",
    "    # https://towardsdatascience.com/random-forest-regression-5f605132d19d\n",
    "    # should be as close to 0 as possible (percentage error)\n",
    "    train_score = nbrs.score(X_train, y_train)\n",
    "\n",
    "    # should be as close to 0 as possible (percentage error)\n",
    "    test_score = nbrs.score(X_test, y_test)\n",
    "\n",
    "    with open(f'/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/knn/picklefiles/line_{line}_model/dir1/line_{line}_nb_metrics.csv', 'w') as file:\n",
    "        file.write(f'\\nTrain metrics for line {line}:' +\n",
    "                   f'\\nScore: {train_score}' +\n",
    "                   f'\\nTest metrics for line {line}:' +\n",
    "                   f'\\nScore: {test_score}'\n",
    "                   )\n",
    "    sum_test_score += test_score\n",
    "    sum_train_score += train_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/k-nearest-neighbor-algorithm-in-python/\n",
    "neighbors = np.arange(1, 9)\n",
    "train_accuracy = np.empty(len(neighbors))\n",
    "test_accuracy = np.empty(len(neighbors))\n",
    "print(\"Printing test accuracy for K Nearest Neighbour model on line\", str(line))\n",
    "# Loop over K values\n",
    "for i, k in enumerate(neighbors):\n",
    "    knn = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    # should be as close to 0 as possible (percentage error)\n",
    "    train_accuracy[i] = knn.score(X_train, y_train)\n",
    "\n",
    "    # should be as close to 0 as possible (percentage error)\n",
    "    test_accuracy[i] = knn.score(X_test, y_test)\n",
    "\n",
    "plt.plot(neighbors, train_accuracy, label='Training dataset accuracy')\n",
    "plt.plot(neighbors, test_accuracy, label='Testing dataset accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('n_neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train score:\", str(sum_train_score/len(lines_dir_1)))\n",
    "print(\"Test score:\", str(sum_test_score/len(lines_dir_1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Features currently in the dataframe:\")\n",
    "print(X_train.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Improving the model**\n",
    "- Initial test score is 0.566 with 8 features.\n",
    "- Features will be dropped from the dataframe as per the previous modelling methods importance of features order.\n",
    "\n",
    "**Step 1**\n",
    "- Drop heavy_precip from the dataframe (now 7 features)\n",
    "    - Mean test score is 0.566\n",
    "- No improvement. Will try next feature.\n",
    "\n",
    "**Step 2**\n",
    "- Drop HOUR (now 6 features)\n",
    "    - Mean test score is 0.574\n",
    "- Improvement shown. Will drop next feature.\n",
    "\n",
    "**Step 3**\n",
    "- Drop weather_id (now 5 features)\n",
    "    - Mean test score is 0.574\n",
    "- No improvement. Will drop next feature.\n",
    "\n",
    "**Step 4**\n",
    "- Drop MONTH (now 4 features)\n",
    "    - Mean test score is 0.574\n",
    "- No improvement. Will return to Random Forest Regressor as predictive modelling method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimising the model\n",
    "\n",
    "Using the 46A line as a baseline I will try to optimise the random forest regressor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = '46A'\n",
    "# dataframe containing only rows with current lineid\n",
    "df_line = df_dir_1[df_dir_1['LINEID'] == line]\n",
    "\n",
    "# randomly generate sequence based on dataframe index and set to be new index\n",
    "df_line.set_index(np.random.permutation(df_line.index))\n",
    "# sort the resulting random index\n",
    "df_line.sort_index(inplace=True)\n",
    "\n",
    "# drop unneeded columns\n",
    "df_line.drop(columns=['LINEID'], inplace=True)\n",
    "\n",
    "X = df_line.drop(columns=[\"TRIPTIME\"], axis=1)\n",
    "y = pd.DataFrame(df_line['TRIPTIME'])\n",
    "\n",
    "# do test train split\n",
    "# Split the dataset into two datasets: 80% training and 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "maxdepth = 20\n",
    "estimators = 20\n",
    "rfr = RandomForestRegressor(\n",
    "    oob_score=True, random_state=1, max_depth=maxdepth, n_estimators=estimators)\n",
    "result = rfr.fit(X_train, y_train)\n",
    "\n",
    "# save the model to a joblib file\n",
    "filename = f'/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/randomforest/testing/line_{line}_model/dir1/mdepth_{maxdepth}_est_{estimators}.joblib'\n",
    "joblib.dump(rfr, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_predictions_train = list(rfr.predict(X_train))\n",
    "rfr_predictions_test = list(rfr.predict(X_test))\n",
    "\n",
    "# choice of metrics from https://medium.com/analytics-vidhya/evaluating-a-random-forest-model-9d165595ad56 and\n",
    "# https://towardsdatascience.com/random-forest-regression-5f605132d19d\n",
    "train_mae = metrics.mean_absolute_error(y_train, rfr_predictions_train)\n",
    "# should be as close to 0 as possible (percentage error)\n",
    "train_mape = metrics.mean_absolute_percentage_error(\n",
    "    y_train, rfr_predictions_train)\n",
    "train_mse = metrics.mean_squared_error(\n",
    "    y_train, rfr_predictions_train)  # as close to 0 as possible\n",
    "train_r2 = metrics.r2_score(y_train, rfr_predictions_train)  # close to 1\n",
    "\n",
    "test_mae = metrics.mean_absolute_error(y_test, rfr_predictions_test)\n",
    "test_mape = metrics.mean_absolute_percentage_error(\n",
    "    y_test, rfr_predictions_test)\n",
    "test_mse = metrics.mean_squared_error(y_test, rfr_predictions_test)\n",
    "test_r2 = metrics.r2_score(y_test, rfr_predictions_test)\n",
    "\n",
    "with open(f'/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/randomforest/testing/line_{line}_model/dir1/mdepth_{maxdepth}_est_{estimators}_metrics.csv', 'w') as file:\n",
    "    file.write(f'\\nTrain metrics for line {line}:'\n",
    "               f'\\nMAE: {train_mae}' +\n",
    "               f'\\nMAPE: {train_mape}' +\n",
    "               f'\\nMSE: {train_mse}' +\n",
    "               f'\\nR2: {train_r2}' +\n",
    "               f'\\nTest metrics for line {line}:'\n",
    "               f'\\nMAE: {test_mae}' +\n",
    "               f'\\nMAPE: {test_mape}' +\n",
    "               f'\\nMSE: {test_mse}' +\n",
    "               f'\\nR2: {test_r2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max depth: 20, n_estimators: 20\n",
      "\n",
      "============Train metrics=============\n",
      "MAE: 177.1496968239207\n",
      "MAPE: 0.045722166090055624\n",
      "MSE: 63186.40418122691\n",
      "R2: 0.9196191564556222\n",
      "============Test metrics=============\n",
      "MAE: 377.42131398206385\n",
      "MAPE: 0.09267623103994643\n",
      "MSE: 254504.53733423146\n",
      "R2: 0.6962318593452395\n"
     ]
    }
   ],
   "source": [
    "print(f\"Max depth: {maxdepth}, n_estimators: {estimators}\\n\")\n",
    "print(\"============Train metrics=============\")\n",
    "print(\"MAE:\", train_mae)\n",
    "print(\"MAPE:\", train_mape)\n",
    "print(\"MSE:\", train_mse)\n",
    "print(\"R2:\", train_r2)\n",
    "\n",
    "print(\"============Test metrics=============\")\n",
    "print(\"MAE:\", test_mae)\n",
    "print(\"MAPE:\", test_mape)\n",
    "print(\"MSE:\", test_mse)\n",
    "print(\"R2:\", test_r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  Metric |Train metrics for 46A before optimisation|Train metrics for 46A after optimisation|\n",
    "|---|---|---|\n",
    "||n_estimators=100, max_depth=None|n_estimators=50, max_depth=None|\n",
    "|MAE|139.1199|141.1095\n",
    "|MAPE|0.03859|0.0392\n",
    "|MSE|40243.7699|41708.15\n",
    "|R2|0.9488|0.9469\n",
    "\n",
    "\n",
    "| Metric  |Test metrics for 46A before optimisation|Test metrics for 46A after optimisation|\n",
    "|---|---|---|\n",
    "||n_estimators=100, max_depth=None|n_estimators=50, max_depth=None|\n",
    "|MAE    |375.629|377.08226\n",
    "|MAPE   |0.09219|0.09255\n",
    "|MSE    |253357.9436|253818.1152\n",
    "|R2 |0.6976|0.69705"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Direction 2\n",
    "Remembering from <i>feature_pairwise_interactions.ipynb</i> the following:\n",
    "* categorical_med_info_gain = ['heavy_precip','weather_id']\n",
    "* categorical_high_info_gain = ['HOUR','WEEKDAY','MONTH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test-train-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dir_2 = pd.read_csv(\n",
    "    '/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/modelling_ready_dir1.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Began model creation for Direction 2 by dropping both 'heavy_precip' from the dataframe as this feature was dropped from direction 1's modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dir_2 = df_dir_2.drop(\n",
    "    columns=['heavy_precip', 'weather_id', 'HOUR'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '102',\n",
       " '104',\n",
       " '11',\n",
       " '111',\n",
       " '114',\n",
       " '116',\n",
       " '120',\n",
       " '122',\n",
       " '123',\n",
       " '13',\n",
       " '130',\n",
       " '14',\n",
       " '140',\n",
       " '142',\n",
       " '145',\n",
       " '14C',\n",
       " '15',\n",
       " '150',\n",
       " '151',\n",
       " '15A',\n",
       " '15B',\n",
       " '15D',\n",
       " '16',\n",
       " '161',\n",
       " '16C',\n",
       " '16D',\n",
       " '17',\n",
       " '17A',\n",
       " '18',\n",
       " '184',\n",
       " '185',\n",
       " '220',\n",
       " '236',\n",
       " '238',\n",
       " '239',\n",
       " '25',\n",
       " '25A',\n",
       " '25B',\n",
       " '25D',\n",
       " '25X',\n",
       " '26',\n",
       " '27',\n",
       " '270',\n",
       " '27A',\n",
       " '27B',\n",
       " '27X',\n",
       " '29A',\n",
       " '31',\n",
       " '31A',\n",
       " '31B',\n",
       " '31D',\n",
       " '32',\n",
       " '32X',\n",
       " '33',\n",
       " '33A',\n",
       " '33B',\n",
       " '33D',\n",
       " '33E',\n",
       " '33X',\n",
       " '37',\n",
       " '38',\n",
       " '38A',\n",
       " '38B',\n",
       " '38D',\n",
       " '39',\n",
       " '39A',\n",
       " '39X',\n",
       " '4',\n",
       " '40',\n",
       " '40B',\n",
       " '40D',\n",
       " '40E',\n",
       " '41',\n",
       " '41B',\n",
       " '41C',\n",
       " '41D',\n",
       " '41X',\n",
       " '42',\n",
       " '42D',\n",
       " '43',\n",
       " '44',\n",
       " '44B',\n",
       " '45A',\n",
       " '46A',\n",
       " '47',\n",
       " '49',\n",
       " '51D',\n",
       " '53',\n",
       " '54A',\n",
       " '56A',\n",
       " '59',\n",
       " '61',\n",
       " '63',\n",
       " '65',\n",
       " '65B',\n",
       " '66',\n",
       " '66A',\n",
       " '66B',\n",
       " '66X',\n",
       " '67',\n",
       " '67X',\n",
       " '68',\n",
       " '68A',\n",
       " '69',\n",
       " '69X',\n",
       " '7',\n",
       " '70',\n",
       " '70D',\n",
       " '75',\n",
       " '76',\n",
       " '76A',\n",
       " '77A',\n",
       " '79',\n",
       " '79A',\n",
       " '7A',\n",
       " '7B',\n",
       " '7D',\n",
       " '83',\n",
       " '83A',\n",
       " '84',\n",
       " '84A',\n",
       " '84X',\n",
       " '9']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_dir_2 = sorted(list(df_dir_2['LINEID'].unique()))\n",
    "lines_dir_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform test-train-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not enough values for line 41D\n"
     ]
    }
   ],
   "source": [
    "# Make dictionaries with keys for each stop with each train/test split value as its values.\n",
    "\n",
    "X_train_dict_2 = {}\n",
    "y_train_dict_2 = {}\n",
    "X_test_dict_2 = {}\n",
    "y_test_dict_2 = {}\n",
    "\n",
    "for line in lines_dir_2:\n",
    "\n",
    "    df_line = df_dir_2[df_dir_2['LINEID'] == line]\n",
    "\n",
    "    # check for df with low values\n",
    "    if df_line.shape[0] < 3:\n",
    "        print('Not enough values for line', str(line))\n",
    "        lines_dir_2.remove(line)\n",
    "\n",
    "    else:\n",
    "        # randomly generate sequence based on dataframe index and set to be new index\n",
    "        df_line.set_index(np.random.permutation(df_line.index))\n",
    "        # sort the resulting random index\n",
    "        df_line.sort_index(inplace=True)\n",
    "\n",
    "        # drop unneeded columns\n",
    "        df_line.drop(columns=['LINEID'], inplace=True)\n",
    "\n",
    "        X = df_line.drop([\"TRIPTIME\"], 1)\n",
    "        y = pd.DataFrame(df_line['TRIPTIME'])\n",
    "\n",
    "        # do test train split\n",
    "        # Split the dataset into two datasets: 70% training and 30% test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "        X_train_dict_2[line] = X_train\n",
    "        y_train_dict_2[line] = y_train\n",
    "        X_test_dict_2[line] = X_test\n",
    "        y_test_dict_2[line] = y_test\n",
    "\n",
    "        # need to reset the index to allow contatenation with predicted values otherwise not joining on same index...\n",
    "        X_train.reset_index(drop=True, inplace=True)\n",
    "        y_train.reset_index(drop=True, inplace=True)\n",
    "        X_test.reset_index(drop=True, inplace=True)\n",
    "        y_test.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict_2 = {}\n",
    "\n",
    "for line in lines_dir_2:\n",
    "    print(f'Line {line}')\n",
    "\n",
    "    X_train_dict_2[line] = X_train\n",
    "    y_train_dict_2[line] = y_train\n",
    "    X_test_dict_2[line] = X_test\n",
    "    y_test_dict_2[line] = y_test\n",
    "\n",
    "    linReg = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "    model_dict_2[line] = linReg\n",
    "\n",
    "    # code from https://stackoverflow.com/questions/11660605/how-to-overwrite-a-folder-if-it-already-exists-when-creating-it-with-makedirs\n",
    "\n",
    "    dir = f'/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/linearregression/picklefiles/line_{line}_model/dir2'\n",
    "    if os.path.exists(dir):\n",
    "        shutil.rmtree(dir)\n",
    "    os.makedirs(dir)\n",
    "\n",
    "    filename = f'/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/linearregression/picklefiles/line_{line}_model/dir2/line_{line}_linreg.sav'\n",
    "    pickle.dump(linReg, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in lines_dir_2:\n",
    "\n",
    "    # training data\n",
    "    X_train = X_train_dict_2[line]\n",
    "    y_train = y_train_dict_2[line]\n",
    "    linReg = model_dict_2[line]\n",
    "\n",
    "    # test data\n",
    "    X_test = X_test_dict_2[line]\n",
    "    y_test = y_test_dict_2[line]\n",
    "    linReg = model_dict_2[line]\n",
    "\n",
    "    print('Now modelling for line', str(line))\n",
    "\n",
    "    linReg_predictions_train = list(linReg.predict(X_train))\n",
    "\n",
    "    # train metrics\n",
    "    train_mae = metrics.mean_absolute_error(y_train, linReg_predictions_train)\n",
    "    train_mape = metrics.mean_absolute_percentage_error(\n",
    "        y_train, linReg_predictions_train)\n",
    "    train_mse = metrics.mean_squared_error(y_train, linReg_predictions_train)\n",
    "    train_rmse = metrics.mean_squared_error(\n",
    "        y_train, linReg_predictions_train)**(0.5)\n",
    "    train_r2 = metrics.r2_score(y_train, linReg_predictions_train)\n",
    "\n",
    "    linReg_predictions_test = list(linReg.predict(X_test))\n",
    "\n",
    "    # test metrics\n",
    "    test_mae = metrics.mean_absolute_error(y_test, linReg_predictions_test)\n",
    "    test_mape = metrics.mean_absolute_percentage_error(\n",
    "        y_test, linReg_predictions_test)\n",
    "    test_mse = metrics.mean_squared_error(y_test, linReg_predictions_test)\n",
    "    test_rmse = metrics.mean_squared_error(\n",
    "        y_test, linReg_predictions_test)**(0.5)\n",
    "    test_r2 = metrics.r2_score(y_test, linReg_predictions_test)\n",
    "\n",
    "    with open(f'/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/linearregression/picklefiles/line_{line}_model/dir2/line_{line}_linreg_metrics.csv', 'w') as file:\n",
    "        file.write(f'\\nTrain metrics for line {line}:'\n",
    "                   f'\\nMAE: {metrics.mean_absolute_error(y_train, linReg_predictions_train)}' +\n",
    "                   f'\\nMAPE: {metrics.mean_absolute_percentage_error(y_train, linReg_predictions_train)}' +\n",
    "                   f'\\nMSE: {metrics.mean_squared_error(y_train, linReg_predictions_train)}' +\n",
    "                   f'\\nRMSE: {metrics.mean_squared_error(y_train, linReg_predictions_train)**(0.5)}' +\n",
    "                   f'\\nR2: {metrics.r2_score(y_train, linReg_predictions_train)}' +\n",
    "                   f'\\nTest metrics for line {line}:'\n",
    "                   f'\\nMAE: {metrics.mean_absolute_error(y_test, linReg_predictions_test)}' +\n",
    "                   f'\\nMAPE: {metrics.mean_absolute_percentage_error(y_test, linReg_predictions_test)}' +\n",
    "                   f'\\nMSE: {metrics.mean_squared_error(y_test, linReg_predictions_test)}' +\n",
    "                   f'\\nRMSE: {metrics.mean_squared_error(y_test, linReg_predictions_test)**(0.5)}' +\n",
    "                   f'\\nR2: {metrics.r2_score(y_test, linReg_predictions_test)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 1\n",
      "Line 102\n",
      "Line 104\n",
      "Line 11\n",
      "Line 111\n",
      "Line 114\n",
      "Line 116\n",
      "Line 120\n",
      "Line 122\n",
      "Line 123\n",
      "Line 13\n",
      "Line 130\n",
      "Line 14\n",
      "Line 140\n",
      "Line 142\n",
      "Line 145\n",
      "Line 14C\n",
      "Line 15\n",
      "Line 150\n",
      "Line 151\n",
      "Line 15A\n",
      "Line 15B\n",
      "Line 15D\n",
      "Line 16\n",
      "Line 161\n",
      "Line 16C\n",
      "Line 16D\n",
      "Line 17\n",
      "Line 17A\n",
      "Line 18\n",
      "Line 184\n",
      "Line 185\n",
      "Line 220\n",
      "Line 236\n",
      "Line 238\n",
      "Line 239\n",
      "Line 25\n",
      "Line 25A\n",
      "Line 25B\n",
      "Line 25D\n",
      "Line 25X\n",
      "Line 26\n",
      "Line 27\n",
      "Line 270\n",
      "Line 27A\n",
      "Line 27B\n",
      "Line 27X\n",
      "Line 29A\n",
      "Line 31\n",
      "Line 31A\n",
      "Line 31B\n",
      "Line 31D\n",
      "Line 32\n",
      "Line 32X\n",
      "Line 33\n",
      "Line 33A\n",
      "Line 33B\n",
      "Line 33D\n",
      "Line 33E\n",
      "Line 33X\n",
      "Line 37\n",
      "Line 38\n",
      "Line 38A\n",
      "Line 38B\n",
      "Line 38D\n",
      "Line 39\n",
      "Line 39A\n",
      "Line 39X\n",
      "Line 4\n",
      "Line 40\n",
      "Line 40B\n",
      "Line 40D\n",
      "Line 40E\n",
      "Line 41\n",
      "Line 41B\n",
      "Line 41C\n",
      "Line 41X\n",
      "Line 42\n",
      "Line 42D\n",
      "Line 43\n",
      "Line 44\n",
      "Line 44B\n",
      "Line 45A\n",
      "Line 46A\n",
      "Line 47\n",
      "Line 49\n",
      "Line 51D\n",
      "Line 53\n",
      "Line 54A\n",
      "Line 56A\n",
      "Line 59\n",
      "Line 61\n",
      "Line 63\n",
      "Line 65\n",
      "Line 65B\n",
      "Line 66\n",
      "Line 66A\n",
      "Line 66B\n",
      "Line 66X\n",
      "Line 67\n",
      "Line 67X\n",
      "Line 68\n",
      "Line 68A\n",
      "Line 69\n",
      "Line 69X\n",
      "Line 7\n",
      "Line 70\n",
      "Line 70D\n",
      "Line 75\n",
      "Line 76\n",
      "Line 76A\n",
      "Line 77A\n",
      "Line 79\n",
      "Line 79A\n",
      "Line 7A\n",
      "Line 7B\n",
      "Line 7D\n",
      "Line 83\n",
      "Line 83A\n",
      "Line 84\n",
      "Line 84A\n",
      "Line 84X\n",
      "Line 9\n"
     ]
    }
   ],
   "source": [
    "rf_model_dict_2 = {}\n",
    "\n",
    "for line in lines_dir_2:\n",
    "    print(f'Line {line}')\n",
    "\n",
    "    X_train_dict_2[line] = X_train\n",
    "    y_train_dict_2[line] = y_train\n",
    "    X_test_dict_2[line] = X_test\n",
    "    y_test_dict_2[line] = y_test\n",
    "\n",
    "    rfr = RandomForestRegressor(\n",
    "        n_estimators=20, max_features=20, oob_score=True, random_state=1)\n",
    "    result = rfr.fit(X_train, y_train)\n",
    "    rf_model_dict_2[line] = result\n",
    "\n",
    "    # code from https://stackoverflow.com/questions/11660605/how-to-overwrite-a-folder-if-it-already-exists-when-creating-it-with-makedirs\n",
    "\n",
    "    dir = f'/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/randomforest/joblibfiles/line_{line}_model/dir2'\n",
    "    if os.path.exists(dir):\n",
    "        shutil.rmtree(dir)\n",
    "    os.makedirs(dir)\n",
    "\n",
    "    filename = f'/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/randomforest/joblibfiles/line_{line}_model/dir2/line_{line}_rfr.joblib'\n",
    "    joblib.dump(result, open(filename, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now modelling for line 1\n",
      "Now modelling for line 102\n",
      "Now modelling for line 104\n",
      "Now modelling for line 11\n",
      "Now modelling for line 111\n",
      "Now modelling for line 114\n",
      "Now modelling for line 116\n",
      "Now modelling for line 120\n",
      "Now modelling for line 122\n",
      "Now modelling for line 123\n",
      "Now modelling for line 13\n",
      "Now modelling for line 130\n",
      "Now modelling for line 14\n",
      "Now modelling for line 140\n",
      "Now modelling for line 142\n",
      "Now modelling for line 145\n",
      "Now modelling for line 14C\n",
      "Now modelling for line 15\n",
      "Now modelling for line 150\n",
      "Now modelling for line 151\n",
      "Now modelling for line 15A\n",
      "Now modelling for line 15B\n",
      "Now modelling for line 15D\n",
      "Now modelling for line 16\n",
      "Now modelling for line 161\n",
      "Now modelling for line 16C\n",
      "Now modelling for line 16D\n",
      "Now modelling for line 17\n",
      "Now modelling for line 17A\n",
      "Now modelling for line 18\n",
      "Now modelling for line 184\n",
      "Now modelling for line 185\n",
      "Now modelling for line 220\n",
      "Now modelling for line 236\n",
      "Now modelling for line 238\n",
      "Now modelling for line 239\n",
      "Now modelling for line 25\n",
      "Now modelling for line 25A\n",
      "Now modelling for line 25B\n",
      "Now modelling for line 25D\n",
      "Now modelling for line 25X\n",
      "Now modelling for line 26\n",
      "Now modelling for line 27\n",
      "Now modelling for line 270\n",
      "Now modelling for line 27A\n",
      "Now modelling for line 27B\n",
      "Now modelling for line 27X\n",
      "Now modelling for line 29A\n",
      "Now modelling for line 31\n",
      "Now modelling for line 31A\n",
      "Now modelling for line 31B\n",
      "Now modelling for line 31D\n",
      "Now modelling for line 32\n",
      "Now modelling for line 32X\n",
      "Now modelling for line 33\n",
      "Now modelling for line 33A\n",
      "Now modelling for line 33B\n",
      "Now modelling for line 33D\n",
      "Now modelling for line 33E\n",
      "Now modelling for line 33X\n",
      "Now modelling for line 37\n",
      "Now modelling for line 38\n",
      "Now modelling for line 38A\n",
      "Now modelling for line 38B\n",
      "Now modelling for line 38D\n",
      "Now modelling for line 39\n",
      "Now modelling for line 39A\n",
      "Now modelling for line 39X\n",
      "Now modelling for line 4\n",
      "Now modelling for line 40\n",
      "Now modelling for line 40B\n",
      "Now modelling for line 40D\n",
      "Now modelling for line 40E\n",
      "Now modelling for line 41\n",
      "Now modelling for line 41B\n",
      "Now modelling for line 41C\n",
      "Now modelling for line 41X\n",
      "Now modelling for line 42\n",
      "Now modelling for line 42D\n",
      "Now modelling for line 43\n",
      "Now modelling for line 44\n",
      "Now modelling for line 44B\n",
      "Now modelling for line 45A\n",
      "Now modelling for line 46A\n",
      "Now modelling for line 47\n",
      "Now modelling for line 49\n",
      "Now modelling for line 51D\n",
      "Now modelling for line 53\n",
      "Now modelling for line 54A\n",
      "Now modelling for line 56A\n",
      "Now modelling for line 59\n",
      "Now modelling for line 61\n",
      "Now modelling for line 63\n",
      "Now modelling for line 65\n",
      "Now modelling for line 65B\n",
      "Now modelling for line 66\n",
      "Now modelling for line 66A\n",
      "Now modelling for line 66B\n",
      "Now modelling for line 66X\n",
      "Now modelling for line 67\n",
      "Now modelling for line 67X\n",
      "Now modelling for line 68\n",
      "Now modelling for line 68A\n",
      "Now modelling for line 69\n",
      "Now modelling for line 69X\n",
      "Now modelling for line 7\n",
      "Now modelling for line 70\n",
      "Now modelling for line 70D\n",
      "Now modelling for line 75\n",
      "Now modelling for line 76\n",
      "Now modelling for line 76A\n",
      "Now modelling for line 77A\n",
      "Now modelling for line 79\n",
      "Now modelling for line 79A\n",
      "Now modelling for line 7A\n",
      "Now modelling for line 7B\n",
      "Now modelling for line 7D\n",
      "Now modelling for line 83\n",
      "Now modelling for line 83A\n",
      "Now modelling for line 84\n",
      "Now modelling for line 84A\n",
      "Now modelling for line 84X\n",
      "Now modelling for line 9\n"
     ]
    }
   ],
   "source": [
    "# sum for averages\n",
    "train_mae_sum = 0\n",
    "train_mape_sum = 0\n",
    "train_mse_sum = 0\n",
    "train_r2_sum = 0\n",
    "\n",
    "test_mae_sum = 0\n",
    "test_mape_sum = 0\n",
    "test_mse_sum = 0\n",
    "test_r2_sum = 0\n",
    "\n",
    "for line in lines_dir_2:  \n",
    "\n",
    "    # training data\n",
    "    X_train = X_train_dict_2[line]\n",
    "    y_train = y_train_dict_2[line]    \n",
    "    # test data\n",
    "    X_test = X_test_dict_2[line]\n",
    "    y_test = y_test_dict_2[line]\n",
    "    rfr = rf_model_dict_2[line]\n",
    "            \n",
    "    print('Now modelling for line', str(line))\n",
    "    \n",
    "    rfr_predictions_train = list(rfr.predict(X_train))\n",
    "    rfr_predictions_test = list(rfr.predict(X_test))\n",
    "\n",
    "    # choice of metrics from https://medium.com/analytics-vidhya/evaluating-a-random-forest-model-9d165595ad56 and\n",
    "    # https://towardsdatascience.com/random-forest-regression-5f605132d19d\n",
    "    train_mae = metrics.mean_absolute_error(y_train, rfr_predictions_train) \n",
    "    train_mape = metrics.mean_absolute_percentage_error(y_train, rfr_predictions_train) # should be as close to 0 as possible (percentage error)\n",
    "    train_mse = metrics.mean_squared_error(y_train, rfr_predictions_train) # as close to 0 as possible\n",
    "    train_r2 = metrics.r2_score(y_train, rfr_predictions_train) #close to 1\n",
    "    \n",
    "    test_mae = metrics.mean_absolute_error(y_test, rfr_predictions_test) \n",
    "    test_mape = metrics.mean_absolute_percentage_error(y_test, rfr_predictions_test) \n",
    "    test_mse = metrics.mean_squared_error(y_test, rfr_predictions_test)\n",
    "    test_r2 = metrics.r2_score(y_test, rfr_predictions_test)\n",
    "\n",
    "\n",
    "    with open(f'/Users/rebeccadillon/git/dublin-bus-team-5/data/modelling/randomforest/joblibfiles/line_{line}_model/dir2/line_{line}_rfr_metrics.csv', 'w') as file:\n",
    "        file.write(f'\\nTrain metrics for line {line}:'\n",
    "                f'\\nMAE: {train_mae}'+\\\n",
    "                f'\\nMAPE: {train_mape}'+\\\n",
    "                f'\\nMSE: {train_mse}'+\\\n",
    "                f'\\nR2: {train_r2}' +\\\n",
    "                f'\\nTest metrics for line {line}:'\n",
    "                f'\\nMAE: {test_mae}'+\\\n",
    "                f'\\nMAPE: {test_mape}'+\\\n",
    "                f'\\nMSE: {test_mse}'+\\\n",
    "                f'\\nR2: {test_r2}')\n",
    "\n",
    "    # sum for averages\n",
    "    train_mae_sum +=train_mae\n",
    "    train_mape_sum +=train_mape\n",
    "    train_mse_sum +=train_mse\n",
    "    train_r2_sum +=train_r2\n",
    "\n",
    "    test_mae_sum += test_mae\n",
    "    test_mape_sum += test_mape\n",
    "    test_mse_sum += test_mse\n",
    "    test_r2_sum += test_r2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============Train metrics=============\n",
      "Mean MAE: 136.11600275807723\n",
      "Mean MAPE: 0.02923740826926568\n",
      "Mean MSE: 35521.41358602242\n",
      "Mean R2: 0.9553417631487555\n",
      "============Test metrics=============\n",
      "Mean MAE: 358.2026248468147\n",
      "Mean MAPE: 0.07758744276053539\n",
      "Mean MSE: 216682.89807213726\n",
      "Mean R2: 0.7423674810278128\n"
     ]
    }
   ],
   "source": [
    "print(\"============Train metrics=============\")\n",
    "print(\"Mean MAE:\", str(train_mae_sum/len(lines_dir_2)))\n",
    "print(\"Mean MAPE:\", str(train_mape_sum/len(lines_dir_2)))\n",
    "print(\"Mean MSE:\", str(train_mse_sum/len(lines_dir_2)))\n",
    "print(\"Mean R2:\", str(train_r2_sum/len(lines_dir_2)))\n",
    "\n",
    "print(\"============Test metrics=============\")\n",
    "print(\"Mean MAE:\", str(test_mae_sum/len(lines_dir_2)))\n",
    "print(\"Mean MAPE:\", str(test_mape_sum/len(lines_dir_2)))\n",
    "print(\"Mean MSE:\", str(test_mse_sum/len(lines_dir_2)))\n",
    "print(\"Mean R2:\", str(test_r2_sum/len(lines_dir_2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PLANNEDTIME_DEP</td>\n",
       "      <td>0.617643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WEEKDAY</td>\n",
       "      <td>0.165472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wind_speed</td>\n",
       "      <td>0.077169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>humidity</td>\n",
       "      <td>0.075806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MONTH</td>\n",
       "      <td>0.063910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           feature  importance\n",
       "2  PLANNEDTIME_DEP    0.617643\n",
       "3          WEEKDAY    0.165472\n",
       "1       wind_speed    0.077169\n",
       "0         humidity    0.075806\n",
       "4            MONTH    0.063910"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = pd.DataFrame(\n",
    "    {'feature': X_train.columns, 'importance': rfr.feature_importances_})\n",
    "importance.sort_values('importance', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|FEATURE|IMPORTANCE|%|\n",
    "|-------|----------|-|\n",
    "|PLANNEDTIME_DEP|0.603|60.3%|\n",
    "|WEEKDAY|0.118|11.8%\n",
    "|wind_speed|0.074|7.4%|\n",
    "|MONTH|0.064|6.4%|\n",
    "|humidity|0.060|6.0%|\n",
    "|HOUR|0.043|4.3%|\n",
    "|weather_id|0.037|3.7%|\n",
    "\n",
    "- The above result shows that PLANNEDTIME_DEP is the most influential on the model at 60%. This means that PLANNEDTIME_DEP accounts for 60% of the variation in TRIPTIME.\n",
    "\n",
    "- Initial mean test MAE is 362.37 or 6 minutes 2 seconds\n",
    "- Initial mean test MAPE is 0.0829 or 8.29%\n",
    "\n",
    "\n",
    "**Improving the model**\n",
    "\n",
    "**Step 1**\n",
    "- Drop weather_id from the dataframe (3.7% importance at present with 7 features)\n",
    "    - Mean test MAE now 357.46 or 5 minutes and 57 seconds\n",
    "    - Mean test MAPE now 0.0819 or 8.19%\n",
    "- MAE and MAPE have decreased showing that the model has improved.\n",
    "\n",
    "**Step 2**\n",
    "- Drop HOUR (4.5% importance at present with 6 features)\n",
    "    - Mean test MAE now 356.73 or 5 minutes and 57 seconds\n",
    "    - Mean test MAPE now 0.0817 or 8.17%\n",
    "- MAE and MAPE have decreased showing that the model has improved.\n",
    "\n",
    "**Step 3**\n",
    "- Drop MONTH (7.2% importance at present with 5 features)\n",
    "    - Mean test MAE now 377.9 or 6 minutes and 18 seconds\n",
    "    - Mean test MAPE now 0.0865 or 8.65%\n",
    "- MAE and MAPE have increased showing that the model has disimproved. We will revert back to the previous step, where the model contains the following five features:\n",
    "    - PLANNEDTIME_DEP\n",
    "    - WEEKDAY\n",
    "    - wind_speed\n",
    "    - MONTH\n",
    "    - humidity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7699efb4af24be428a0b5648dfa7aba129b905e3165e555843cf88f6106e2e55"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('rp22')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
