{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Before beginning the data quality report I import the data set and remove all rows which contain weather data outside of the required time period (i.e., the year 2018). Although this could have been completed later, it meant that the dataset was dramatically reduced in size and therefore quicker and easier to work with throughout the DQR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Feature|Description|Unit|\n",
    "|---|---|---|\n",
    "|dt|Time of data calculation|UTC|\n",
    "|dt_iso|Date and time in UTC format|UTC|\n",
    "|timezone|Shift in seconds from UTC|seconds|\n",
    "|city_name|City name|   |\n",
    "|lat|Geographical coordinates of the location (latitude)||\n",
    "|lon|Geographical coordinates of the location (longitude)||\n",
    "|temp|temperature|degrees celcius|\n",
    "|visibility|Average visibility. The maximum value of the visibility is 10km.| metres|\n",
    "|dew_point|Atmospheric temperature (varying according to pressure and humidity) below which water droplets begin to condense and dew can form|degrees celcius|\n",
    "|feels_like|This temperature parameter accounts for the human perception of weather|degrees celcius|\n",
    "|temp_min|Minimum temperature at the moment. This is deviation from temperature that is possible for large cities and megalopolises geographically expanded|degrees celcius|\n",
    "|temp_max|Maximum temperature at the moment. This is deviation from temperature that is possible for large cities and megalopolises geographically expanded|degrees celcius|\n",
    "|pressure| Atmospheric pressure (on the sea level)|hPa|\n",
    "|sea_level| |   |\n",
    "|grnd_level|    |   |\n",
    "|humidity|humidity|%|\n",
    "|wind_speed| Wind speed| meter/sec|\n",
    "|wind_deg|Wind direction|degrees (meterorological|\n",
    "|wind_gust|wind gust|meter/sec|\n",
    "|rain_1h|Rain volume for the last hour| mm|\n",
    "|rain_3h|Rain volume for the last 3 hours| mm|\n",
    "|snow_1h|Snow volume for the last hour, (in liquid state)| mm|\n",
    "|snow_3h|Snow volume for the last 3 hours, (in liquid state)| mm|\n",
    "|clouds_all|Cloudiness| %|\n",
    "|weather_id|Weather condition ID|   |\n",
    "|weather_main|Group of weather parameters (Rain, Snow, Extreme etc.)|   |\n",
    "|weather_description|Weather condition within the group|    |\n",
    "|weather_icon|Weather icon ID|  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/rebeccadillon/git/dublin-bus-team-5/machinelearning/data/raw_data/dublin_weather_2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 9060 rows of data across 28 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some descriptive statistucs of the df\n",
    "df.describe(datetime_is_numeric=True).T "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the columns 'sea_level','grnd_level','rain_3h' and 'snow_3h' contain zero values and will be dropped from the dataframe. \n",
    "\n",
    "Columns to be dropped so far:\n",
    "* sea_level\n",
    "* grnd_level\n",
    "* rain_3h\n",
    "* snow_3h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change dt_iso column to datetime. Code from https://www.datasciencesociety.net/weather-proof-mobility/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dt_iso'] = df['dt_iso'].apply(lambda x: pd.to_datetime(x[:-10], infer_datetime_format=True))\n",
    "df['dt_iso']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select all columns with object datatype\n",
    "categorical_cols = df.select_dtypes(['object']).columns\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select columns with categorical data and add to list\n",
    "categorical_cols = categorical_cols.append(df[['timezone', 'weather_id']].columns)\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert columns in the list to categorical columns\n",
    "for col in categorical_cols:\n",
    "    df[col] = df[col].astype('category')\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_cols = df.select_dtypes(['float64','datetime64[ns]','int64']).columns\n",
    "continuous_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for duplicate rows and null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicate rows\n",
    "df.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are additional colums with missing values, 'visibility','wind_gust','rain_1h' and 'snow_1h' which will be examined further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results above show that the columns 'city_name','lat' and 'lon' contain just one unique value and so the information gain from these columns is likely limited. The use of these columns will be futher examined and they may be dropped from the dataframe later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the logical integrity of the data\n",
    "#### Continuous features\n",
    "I will first check that there are no negative values in columns which should not logically hold negative values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(datetime_is_numeric=True).T "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observing the continuous data there are no obvious signs of illogical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the rows are within the required dates \n",
    "test_timeframe = df['dt_iso'].dt.year == 2018\n",
    "test_timeframe.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove these rows from the dataframe\n",
    "# drop rows not in 2018\n",
    "# https://sparkbyexamples.com/pandas/pandas-delete-rows-based-on-column-value/\n",
    "df.drop(df[df['dt_iso'].dt.year != 2018].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorical columns\n",
    "Check all data is for Dublin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['city_name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive statistics\n",
    "## Continuous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print descriptive stats for the continuous columns\n",
    "# descriptive column\n",
    "con_descriptive_df = df[continuous_cols].describe(datetime_is_numeric=True).T \n",
    "con_descriptive_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continous_figs_pdf = PdfPages('/Users/rebeccadillon/git/dublin-bus-team-5/data_prep/documents/figs/dqr_openweather_continuous_barcharts.pdf')\n",
    "for col in continuous_cols:\n",
    " fig = df[col].hist(figsize=(15,5))\n",
    " plt.title(col)\n",
    " continous_figs_pdf.savefig(fig.get_figure(),bbox_inches='tight')\n",
    " plt.show()\n",
    "\n",
    "continous_figs_pdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print descriptives for categorical columns\n",
    "cardinality = df[categorical_cols].nunique()\n",
    "cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_count = df[categorical_cols].isnull().sum()\n",
    "null_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_figs_pdf = PdfPages('/Users/rebeccadillon/git/dublin-bus-team-5/data_prep/documents/figs/dqr_openweather_categorical_barcharts.pdf')\n",
    "\n",
    "for col in categorical_cols:\n",
    "    fig = df[col].value_counts(dropna=True).plot(kind='bar', title=col, figsize=(15,5), color='rebeccapurple')\n",
    "    plt.title(col)\n",
    "    categorical_figs_pdf.savefig(fig.get_figure(),bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "categorical_figs_pdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality Plan\n",
    "Initial list of issues identified in the Data Quality Report\n",
    "\n",
    "|Feature|Data Quality Issue|Action|\n",
    "|---|---|---|\n",
    "|dt| Similar to dt_iso|Drop column   |\n",
    "|dt_iso|  No issue|keep column   |\n",
    "|timezone|Low information gain | Drop column  |\n",
    "|city_name|Low information gain | Drop column  |\n",
    "|lat|Low information gain | Drop column  |\n",
    "|lon|Low information gain | Drop column  |\n",
    "|temp| |   |\n",
    "|visibility| missing values| investigate further, drop if necessary  |\n",
    "|dew_point| |   |\n",
    "|feels_like| |   |\n",
    "|temp_min| |   |\n",
    "|temp_max| |   |\n",
    "|pressure| |   |\n",
    "|sea_level|Null column | Drop column  |\n",
    "|grnd_level| Null column | Drop column  |\n",
    "|humidity| |   |\n",
    "|wind_speed| |   |\n",
    "|wind_deg| |   |\n",
    "|wind_gust| missing values|investigate further, drop if necessary  |\n",
    "|rain_1h| missing values| replace with 0  |\n",
    "|rain_3h|Null column | Drop column  |\n",
    "|snow_1h|missing values| replace with 0  |\n",
    "|snow_3h|Null column | Drop column  |\n",
    "|clouds_all| |   |\n",
    "|weather_id| |   |\n",
    "|weather_main| |   |\n",
    "|weather_description| |   |\n",
    "|weather_icon| Low information gain|Drop column   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per the issues identified in the DQR above, the following columns can be dropped from the dataframe:\n",
    "* dt\n",
    "* timezone\n",
    "* city_name\n",
    "* lat\n",
    "* lon\n",
    "* sea_level\n",
    "* grnd_level\n",
    "* rain_3h\n",
    "* snow_3h\n",
    "* weather_icon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['dt','timezone','city_name','lat','lon','sea_level','grnd_level','rain_3h', 'snow_3h','weather_icon'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rain_1h'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Change NaN values in 'rain_1h' and 'snow_1h' to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rain_1h'] = df['rain_1h'].fillna(0)\n",
    "df['snow_1h'] = df['snow_1h'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create a column 'snow_ice' which flags values below 0 in the 'temp' column OR where there is a value above 0 for 'snow_1h' OR where snow is indicated in 'weather_main' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['snow_ice'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['temp'] <= 0, 'snow_ice'] =  1\n",
    "df.loc[df['snow_1h'] > 0, 'snow_ice'] = 1\n",
    "df.loc[df['weather_main'] == 'Snow', 'snow_ice'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['snow_ice']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. I will create a boolean column named 'heavy_precip' which will indicate heavy rain or snow fall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['heavy_precip'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[df['rain_1h'] <= 0, 'heavy_precip'] =  1\n",
    "#df.loc[df['snow_1h'] <= 0, 'heavy_precip'] =  1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rain_1h'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['snow_1h'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The open weather website has condition codes which map to the weather_id, weather_main and weather_description columns in this dataframe. Among these codes are the following \n",
    "|ID\t|Main\t|Description\t|\n",
    "|---|----|----|\n",
    "500\tRain\tlight rain\t\n",
    "501\tRain\tmoderate rain\t\n",
    "502\tRain\theavy intensity rain\n",
    "503\tRain\tvery heavy rain\t\n",
    "504\tRain\textreme rain\t\n",
    "511\tRain\tfreezing rain\t\n",
    "520\tRain\tlight intensity shower rain\t\n",
    "521\tRain\tshower rain\t\n",
    "522\tRain\theavy intensity shower rain\t \n",
    "531\tRain\tragged shower rain\t \n",
    "\n",
    "from this list, for the purpose of defining heavy rain I will take the following IDs to identifying rows with 'heavy' rain:\n",
    "501,502,503,504,511,521,522,531"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raining = df.loc[df['weather_id'].isin([501,502,503,504,511,521,522,531])]\n",
    "df_raining['weather_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this dataframe only contains values for 'moderate rain','heavy intensity rain' and 'shower rain'. I will now plot a histogram to show the distribution of rain values for these weather descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raining['rain_1h'].hist(figsize=(15,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will also print some descriptive statistics of this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raining.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above describes the 'min' rain per hour value as zero. I will instead go with the Q1 value of 1.06, or greater than 1mm rain per hour to indicate 'heavy' rain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['rain_1h'] > 1, 'heavy_precip'] = 1\n",
    "df.loc[df['heavy_precip']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving onto the snow, the following condition codes which map to the weather_id column in this dataframe were taken from the open weather website. Among these codes are the following codes for snow:\n",
    "\n",
    "\n",
    "|ID\t|Main\t|Description\t|Icon|\n",
    "|---|---|---|---|\n",
    "600\tSnow\tlight snow\t \n",
    "601\tSnow\tSnow\t \n",
    "602\tSnow\tHeavy snow\t \n",
    "611\tSnow\tSleet\t \n",
    "612\tSnow\tLight shower sleet\t \n",
    "613\tSnow\tShower sleet\t \n",
    "615\tSnow\tLight rain and snow\t \n",
    "616\tSnow\tRain and snow\t \n",
    "620\tSnow\tLight shower snow\t \n",
    "621\tSnow\tShower snow\t \n",
    "622\tSnow\tHeavy shower snow\t\n",
    "\n",
    "\n",
    "From the above codes, I will identify which of these codes are in my dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snowing = df.loc[df['weather_id'].isin([600,601,602,611,612,613,615,616,620,621,622])]\n",
    "df_snowing['weather_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above result shows that 'light snow','snow','light shower sleet','light shower snow' and 'shower snow' are in the dataframe. I will omit those that are described as 'light', and just include the others in defining 'heavy precipitation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snowing['snow_1h'].hist(figsize=(15,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snowing.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the minimum value for snow over the past hour is 0. I will omit the categories labelled 'light' and print some descriptives again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snowing = df.loc[df['weather_id'].isin([601,621])]\n",
    "df_snowing.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_snowing['snow_1h'].hist(figsize=(15,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above figure shows that the majority of rows have snow_1h values of 0.5 and above. For this reason I will place my snow threshold at 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['snow_1h'] > 0.5, 'heavy_precip'] = 1\n",
    "df.loc[df['heavy_precip']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Visibility missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['visibility'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['visibility'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will see what relationship these values have with other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar_plot(col1, col2):\n",
    "    df.groupby(col1)[col2].mean().plot.bar(cmap='Pastel2')\n",
    "    plt.title(col1 + \" vs \" + col2)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = df.select_dtypes(['category']).columns\n",
    "categorical_cols = categorical_cols.append(df[['snow_ice', 'heavy_precip']].columns)\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_cols = df.select_dtypes(['int64','float64','datetime64[ns]']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['visibility_null'] = 0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['visibility'].isnull(), 'visibility_null'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in continuous_cols:\n",
    "    bar_plot('visibility_null', col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical_cols:\n",
    "    sns.histplot(binwidth=0.5, x='visibility_null', hue=col, data=df, stat=\"count\", multiple=\"stack\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear from the above figures that the null values are in relation to cloud cover. As the nature of the visibility column means it is influenced by a variety of weather factors (rain, snow, cloud cover, fog etc), I will drop this column from the dataframe as it does not appear to add much information to the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['visibility','visibility_null'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Wind gust\n",
    "\n",
    "\n",
    "The wind gust column contained missing values where the visibility column also held missing values. I will repeat the same steps as I did with the visibility column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['wind_gust'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this column contains a lot of missing values and as we have a lot of other columns with useful weather information, I will drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['wind_gust'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cleaned dataframe to new file\n",
    "df.to_csv('/Users/rebeccadillon/git/dublin-bus-team-5/machinelearning/data/cleaned/dublin-weather-2018-cleaned-dqp.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7699efb4af24be428a0b5648dfa7aba129b905e3165e555843cf88f6106e2e55"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('rp22')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
